{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  clases genericas\n",
    "import numpy as np\n",
    "import os\n",
    "#import pickle\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dropout, Dense, Input, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.metrics import  confusion_matrix, roc_auc_score, f1_score,  precision_score, recall_score #, roc_curve, auc\n",
    "\n",
    "\n",
    "from keras.preprocessing import image as keras_image\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "from keras_efficientnets import *\n",
    "from keras_efficientnets import preprocess_input  \n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.applications.nasnet import preprocess_input    \n",
    "from tensorflow.keras.applications.xception import preprocess_input    \n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input    \n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Definir paths em meu computador                 \n",
    "\n",
    "Path_open_csv =  '/home/karem/Artigo_Periodico/1_Dataset/CSV_Files/'\n",
    "Path_images =  '/home/karem/Artigo_Periodico/1_Dataset/1_Original_size640/'\n",
    "Path_save_result = '/home/karem/Artigo_Periodico/Classifier/Result/'  ## definir pasta onde salvar pesos e log\n",
    "Path_Open_peso   =  '/home/karem/Artigo_Periodico/Classifier/Experiment/'  ## definir pasta onde salvar pesos e log\n",
    "\n",
    "term_imagem = '.png'\n",
    "\n",
    "\n",
    "###############################################################################################\n",
    "#          Definicion de parametros de treinamento\n",
    "################################################################################################\n",
    "\n",
    "### Definir parâmetros\n",
    "width       = 32*8*1\n",
    "height      = 32*8*1\n",
    "depth       = 3                 # 3 se RGB, 1 se grayscale (weights_ini= None)\n",
    "inputShape  = (height, width, depth)\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#                   carregar e montar csv de treino e validação\n",
    "################################################################################################\n",
    "### carregar e montar csv de treino e validação\n",
    "data_test = pd.DataFrame()\n",
    "data_test_temp = pd.read_csv(Path_open_csv + 'test.csv').rename(columns={'id': 'image_id', 'class_name': 'label'})\n",
    "data_test_temp['label'].replace({'negative': 0, 'typical': 1, 'indeterminate': 1}, inplace=True)\n",
    "\n",
    "data_test_temp['Image_name'] = data_test_temp['image_id'].replace('_image', '', regex=True) + term_imagem\n",
    "data_test = data_test_temp[['Image_name', 'label']]\n",
    "\n",
    "data_test['classVector'] = data_test['label']\n",
    "data_test['Image_Index'] = Path_images + data_test['Image_name'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados de salvamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rede = ['DenseNet121', 'DenseNet169', 'DenseNet201', \\\n",
    "#         'InceptionV3', 'InceptionResNetV2', \\\n",
    "#         'MobileNet', 'MobileNetV2', \\\n",
    "#         'NASNetLarge', 'NASNetMobile', \\\n",
    "#         'ResNet50', 'ResNet101', 'ResNet152', 'ResNet50V2', 'ResNet101V2', 'ResNet152V2', \\\n",
    "#         'VGG16', 'VGG19', \\\n",
    "#         'Xception']\n",
    "\n",
    "# rede = ['EfficientNetB0', 'EfficientNetB1', 'EfficientNetB2', 'EfficientNetB3', 'EfficientNetB4', \\\n",
    "#         #'EfficientNetB5', 'EfficientNetB6', 'EfficientNetB7', \\\n",
    "#         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rede =  'NASNetLarge'\n",
    "\n",
    "weights_ini = 'imagenet'  # 'imagenet'  None\n",
    "NUM_EPOCHS = 80\n",
    "BATCH_SIZE  = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "#                                Dados do treino \n",
    "################################################################################################\n",
    "\n",
    "l_nome_proceso = 'CNN_mlp'\n",
    "experimento = l_nome_proceso + '_WH_' + str(width) \n",
    "\n",
    "### definir pasta onde esta o peso treinado\n",
    "Path_Open_peso_bes   = Path_Open_peso + '/Models/' + experimento +  '/'\n",
    "\n",
    "### Criar pastas onde estão os pesos\n",
    "#create_folders(Path_Open_peso)\n",
    "create_folders(Path_save_result)\n",
    "\n",
    "### definir nomes de arquivos de saida\n",
    "palavra_s = 'ensaio_' + rede + '_' + weights_ini + '_WH_' + str(width)       \n",
    "arquivo_best_peso = os.path.sep.join([Path_Open_peso_bes, palavra_s + \".hdf5\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_GeneratorRx(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data_path_img, data_lab, index_b, batch_size=BATCH_SIZE, inputShape=inputShape, aug = 0, shuffle=True):            \n",
    "        'Initialization'\n",
    "        if aug == 1:\n",
    "            data_gen = ImageDataGenerator(  \n",
    "                                        rotation_range     = 15,\n",
    "                                        # zoom_range         = 0.05,\n",
    "                                        width_shift_range  = 0.1,\n",
    "                                        height_shift_range = 0.1,\n",
    "                                        # shear_range        = 0.01,\n",
    "                                        horizontal_flip    = True,\n",
    "                                        fill_mode          = \"nearest\",\n",
    "                                        preprocessing_function = preprocess_input,\n",
    "                                        )\n",
    "        else:\n",
    "            data_gen = ImageDataGenerator(\n",
    "                                    preprocessing_function = preprocess_input, # se usar isto a imagem entrada deve ficar 0-255\n",
    "                                 )            \n",
    "        self.data_path_img  =  data_path_img   \n",
    "        self.labels         =  data_lab   \n",
    "        self.index_b        =  index_b    \n",
    "        self.batch_size     =  batch_size # int\n",
    "        self.inputShape     =  inputShape               # tuple int)\n",
    "        self.data_gen       =  data_gen\n",
    "        self.shuffle        =  shuffle\n",
    "        self.aug            =  aug\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "####################################################################################################################################\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\n",
    "        :return: number of batches per epoch        \"\"\"\n",
    "        return int(np.ceil( len(self.data_path_img)  /  float(self.batch_size) ))\n",
    "    \n",
    "####################################################################################################################################\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\n",
    "        :param index: index of the batch\n",
    "        :return: X and y when fitting. X only when predicting\n",
    "        \"\"\"\n",
    "        ## Generate indexes of the batch\n",
    "        indexes = self.index_b[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        ## Find list of IDs (paths)\n",
    "        list_IDs_temp = [self.data_path_img[k] for k in indexes]\n",
    "        ## Generate data\n",
    "        X = self._generate_X(list_IDs_temp)\n",
    "        y = self.labels[indexes]                \n",
    "        ## Generate Augmented data\n",
    "        iterat = self.data_gen.flow(X, y, shuffle=self.shuffle)\n",
    "        X0,y0  = iterat.next()\n",
    "        y_mat  = np.array(np.uint32 (y0.tolist()) )\n",
    "        return X0,y_mat\n",
    "    \n",
    "####################################################################################################################################\n",
    "    def _generate_X(self, list_IDs_temp):\n",
    "        \"\"\"Generates data containing batch_size images\n",
    "        :param list_IDs_temp: list of image paths to load\n",
    "        :return: batch of images\n",
    "        \"\"\"\n",
    "        # Initialization\n",
    "        X = np.empty( (len(list_IDs_temp), *self.inputShape) )\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            X[i,] = self._load_image(ID)\n",
    "        return X\n",
    "    \n",
    "####################################################################################################################################\n",
    "    def _load_image(self, image_path):\n",
    "        \"\"\"Load grayscale image\n",
    "        :param image_path: path to image to load\n",
    "        :return: loaded image\n",
    "        \"\"\"\n",
    "        img = keras_image.load_img(image_path ,target_size=self.inputShape,interpolation='bicubic',color_mode = \"rgb\")\n",
    "        img = 255.0*np.array(img) / (1.0*np.nanmax(img))\n",
    "        return img   #  [0,255]\n",
    "    \n",
    "####################################################################################################################################\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.index_b = np.arange(len(self.data_path_img))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.index_b)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, model_weights_ini, inputShape):        \n",
    "    if model_name   == 'ResNet50V2':                 \n",
    "        base_model = ResNet50V2(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape))\n",
    "    \n",
    "    elif model_name == 'VGG16':          \n",
    "        base_model = VGG16(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape))\n",
    "    \n",
    "    elif model_name == 'VGG19':            \n",
    "        base_model = VGG19(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape))\n",
    "        \n",
    "    elif model_name == 'EfficientNetB4':        \n",
    "        base_model = EfficientNetB4(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape))   \n",
    "        \n",
    "    elif model_name == 'EfficientNetB0':  \n",
    "        base_model = EfficientNetB0(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape))\n",
    "        \n",
    "    elif model_name == 'MobileNetV2':             \n",
    "        base_model = MobileNetV2(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape)) \n",
    "    \n",
    "    elif model_name == 'DenseNet201':             \n",
    "        base_model = DenseNet201(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape))   \n",
    "    \n",
    "    elif model_name == 'NASNetLarge':             \n",
    "        base_model = NASNetLarge(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape)) \n",
    "        \n",
    "    elif model_name == 'Xception':             \n",
    "        base_model = Xception(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape))   \n",
    "        \n",
    "    elif model_name == 'InceptionV3':             \n",
    "        base_model = InceptionV3(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape))   \n",
    "        \n",
    "    elif model_name == 'InceptionResNetV2':             \n",
    "        base_model = InceptionResNetV2(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape))   \n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### definir dictionario para apontador dentro do generator\n",
    "paramsB = {\n",
    "              'batch_size': BATCH_SIZE,\n",
    "              'inputShape': inputShape,\n",
    "          } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "#                  Montar CONV net\n",
    "################################################################################################\n",
    "##  carregar modelo base\n",
    "base_model = get_model(rede, weights_ini, inputShape)\n",
    "## construir MLP\n",
    "headModel = base_model.output\n",
    "headModel = GlobalAveragePooling2D()(headModel)\n",
    "headModel = BatchNormalization()(headModel)\n",
    "headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.3)(headModel)                      # orig = 0.5\n",
    "headModel = Dense(1, activation=\"sigmoid\", name=\"pred\")(headModel)\n",
    "\n",
    "## place the head FC model on top of the base model (this will become the actual model we will train)\n",
    "model = Model(inputs=base_model.input, outputs=headModel, name=\"Classifica\")\n",
    "\n",
    "## carregar pesos\n",
    "model.load_weights(arquivo_best_peso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "#                  Montar generator\n",
    "################################################################################################  \n",
    "test_generator  =  Data_GeneratorRx(data_path_img = data_test['Image_Index']  , data_lab = data_test['classVector']  , index_b = np.arange(len(data_test)), **paramsB, aug = 0,shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "#                  predecir\n",
    "################################################################################################\n",
    "y_pred = model.predict(test_generator,    verbose=1  )\n",
    "y_true = np.array(np.uint32 (data_test['classVector'].tolist()) ).reshape(len(data_test['classVector']),1)\n",
    "      \n",
    "## Assumir  threshold\n",
    "threshold = [0.5]\n",
    "AUC     = roc_auc_score(y_true, y_pred)  \n",
    "\n",
    "## Find prediction  applying threshold\n",
    "y_pred_bin = np.array([1 if prob >= threshold else 0 for prob in y_pred])\n",
    "y_pred_bin = y_pred_bin.reshape([len(y_pred_bin),1])\n",
    "\n",
    "## Calcular metricas\n",
    "tn0, fp0, fn0, tp0 = confusion_matrix(y_true , y_pred_bin).ravel()\n",
    "f1    = f1_score(y_true, y_pred_bin, average='binary')\n",
    "acc   = (tp0 + tn0) / (tp0 + tn0 + fp0+ fn0)\n",
    "ps    = precision_score(y_true , y_pred_bin)\n",
    "rec   = recall_score(y_true , y_pred_bin)\n",
    "\n",
    "## salvar metricas\n",
    "metricas = np.zeros([y_pred.shape[1],12])\n",
    "metricas[:] = [0,0, threshold[0],tp0, fp0, tn0, fn0, AUC, f1 , acc, ps, rec]\n",
    "salida   = pd.DataFrame(metricas).rename(columns={0:'rede', 1:'Base',  2:'threshold',3:'TP', 4:'FP', 5:'TN', 6:'FN', 7:'AUROC', 8:'F1', 9:'acc', 10:'prec', 11: 'rec'})\n",
    "salida['Base'] = 'exemplo cnn'\n",
    "salida['rede'] = rede\n",
    "\n",
    "#salida.to_csv(Path_save_result + 'res_' + rede + '_' + weights_ini + '_WH_' + str(width) + '.csv' , index = False)\n",
    "#salida.to_csv(Path_save_result + 'res_' + rede + '_' + weights_ini + '_WH_' + str(width) + '_ep_' + str(ep) + '.csv' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o resultado no arquivo csv\n",
    "#salida.to_csv(Path_save_result + 'res_' + rede + '_' + weights_ini + '_WH_' + str(width) + '.csv' , index = False)\n",
    "\n",
    "# Se o arquivo não existir, irá criar e salvar os dados da predição\n",
    "if not os.path.isfile(Path_save_result + 'result_' + weights_ini + '_WH_' + str(width) + '.csv'):\n",
    "    salida.to_csv(Path_save_result + 'result_' + weights_ini + '_WH_' + str(width) + '.csv', index = False)    \n",
    "else: # caso contrário irá concatenar o que existe com os dados de outras redes\n",
    "    df_1 = pd.read_csv(Path_save_result + 'result_' + weights_ini + '_WH_' + str(width) + '.csv') # dado existente no csv\n",
    "    df_2 = salida # dado obtido na última predição\n",
    "    \n",
    "    result = pd.concat([df_1, df_2], axis = 0) # concatenate vertically (linhas) / se axis = 1 => concatenate horizontally (colunas)\n",
    "    result = result.reset_index(drop = True) # reinicia o index\n",
    "    result.to_csv(Path_save_result + 'result_' + weights_ini + '_WH_' + str(width) + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
