{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b191ee3",
   "metadata": {},
   "source": [
    "## Gerar Labels\n",
    "convert nomalize data (xcenter, ycenter, w, h) to original Voc (x1, y1, x2, y2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d437954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d93f957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karem/anaconda3/envs/env_py39/lib/python3.9/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>width_roi</th>\n",
       "      <th>height_roi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>888109901b29_image</td>\n",
       "      <td>covid</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>[88.0, 332.0]</td>\n",
       "      <td>[158.0, 179.0]</td>\n",
       "      <td>[276.0, 499.0]</td>\n",
       "      <td>[413.0, 506.0]</td>\n",
       "      <td>[188.0, 167.0]</td>\n",
       "      <td>[255.0, 327.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35a789322c1d_image</td>\n",
       "      <td>normal</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>462a64ef01e3_image</td>\n",
       "      <td>normal</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>952d4a77beda_image</td>\n",
       "      <td>covid</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>[404.0]</td>\n",
       "      <td>[335.0]</td>\n",
       "      <td>[517.0]</td>\n",
       "      <td>[459.0]</td>\n",
       "      <td>[113.0]</td>\n",
       "      <td>[124.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96417c620956_image</td>\n",
       "      <td>covid</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>[101.0, 401.0]</td>\n",
       "      <td>[214.0, 258.0]</td>\n",
       "      <td>[212.0, 513.0]</td>\n",
       "      <td>[473.0, 547.0]</td>\n",
       "      <td>[111.0, 111.0]</td>\n",
       "      <td>[259.0, 289.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id class_name  width  height            xmin  \\\n",
       "0  888109901b29_image      covid    640     640   [88.0, 332.0]   \n",
       "1  35a789322c1d_image     normal    640     640           [0.0]   \n",
       "2  462a64ef01e3_image     normal    640     640           [0.0]   \n",
       "3  952d4a77beda_image      covid    640     640         [404.0]   \n",
       "4  96417c620956_image      covid    640     640  [101.0, 401.0]   \n",
       "\n",
       "             ymin            xmax            ymax       width_roi  \\\n",
       "0  [158.0, 179.0]  [276.0, 499.0]  [413.0, 506.0]  [188.0, 167.0]   \n",
       "1           [0.0]           [0.0]           [0.0]           [0.0]   \n",
       "2           [0.0]           [0.0]           [0.0]           [0.0]   \n",
       "3         [335.0]         [517.0]         [459.0]         [113.0]   \n",
       "4  [214.0, 258.0]  [212.0, 513.0]  [473.0, 547.0]  [111.0, 111.0]   \n",
       "\n",
       "       height_roi  \n",
       "0  [255.0, 327.0]  \n",
       "1           [0.0]  \n",
       "2           [0.0]  \n",
       "3         [124.0]  \n",
       "4  [259.0, 289.0]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "carrega o arquivo com o nome e tamanho das imagens do conjunto de teste\n",
    "'''\n",
    "\n",
    "# df = pd.read_csv('/home/karem/Artigo_Periodico/1_Dataset/CSV_Files/Folder_1_Covid/test.csv')\n",
    "df = pd.read_csv('/home/karem/Artigo_Periodico/1_Dataset/CSV_Files/2class_trainCovidNormal/test.csv')\n",
    "\n",
    "# # coloca a extensão .png no final do nome da imagem\n",
    "# #df['id'] = df['id'].apply(lambda x: x.replace('_image', '.png'))\n",
    "# #df[['id']] = df[['id']] + '.png'\n",
    "\n",
    "# ### Remove os casos negativos\n",
    "# indexNames = df[df['class_name'] == 'negative'].index\n",
    "# # Delete these row indexes from dataFrame\n",
    "# df.drop(indexNames, inplace = True)\n",
    "\n",
    "\n",
    "# # reinicia o index\n",
    "# df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "df['class_name'].loc[(df['class_name'] == 'typical')] = 'covid'\n",
    "df['class_name'].loc[(df['class_name'] == 'indeterminate')] = 'covid'\n",
    "\n",
    "df['class_name'].loc[(df['class_name'] == 'negative')] = 'normal'\n",
    "\n",
    "print(len(df))\n",
    "df.head(5)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c754141",
   "metadata": {},
   "source": [
    "#### Create files -> GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f069bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lista para string\n",
    "def convert(lst):\n",
    "    i = ''.join(lst)\n",
    "    str1 = re.sub(r\"[\\([{})\\]]\", \"\", i)\n",
    "    return str1\n",
    "\n",
    "#Cria o dietório caso não exista\n",
    "def create_folders(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "# se houver a pasta, ela é removida\n",
    "import shutil\n",
    "def remove_folders(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "        \n",
    "# Converte string para lista\n",
    "def Convert_str_to_int(string):\n",
    "    li = list(string.split(\", \"))\n",
    "    return li\n",
    "\n",
    "import re\n",
    "def convert_df_lista_int(str1):\n",
    "    #str1 = df['xmin_ori'][1]\n",
    "    str1 = re.sub(r\"[\\([{})\\]]\", \"\", str1) # remove os caracteres da string\n",
    "    #str1 = (str1.replace('.0', '')) # substirui a casa decimal .0 por vazio, tornando a string no formato int\n",
    "    str1 = Convert_str_to_int(str1) # converte a string em lista\n",
    "    #str1 = list(map(float, str1)) # converte a lista de string em float\n",
    "    #str1 = list(map(int, str1)) # converte a lista de float em int\n",
    "    str1 = [int(float(i)) for i in str1] # convert os valores para inteiro e depois string    \n",
    "    return str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c908fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera os labels do GT\n",
    "\n",
    "#path\n",
    "path_labelsGT = '/home/karem/Artigo_Periodico/Detector/Ensemble/labels/ground_truth/'\n",
    "\n",
    "remove_folders(path_labelsGT)\n",
    "create_folders(path_labelsGT)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    \n",
    "    # cria um txt com os nomes das imagens\n",
    "    # substitui o .png do dataframe para txt\n",
    "    nome_file = os.path.basename(df.iloc[i,0].replace('_image', '.txt'))\n",
    "    \n",
    "    # cria o arquivo txt no modo escrita (w)\n",
    "    file = open(path_labelsGT + nome_file, \"w\") \n",
    "#     if not (os.path.exists(path_labels_pred + nome_file)): # se o arquivo txt não existir (se a yolo nõa gerou label)\n",
    "#         print(nome_file)\n",
    "#         file2 = open(path_labels_pred + nome_file, \"w\")\n",
    "#         file2.write('0 0 0 0 0 0') # salva no txt       \n",
    "    \n",
    "    lista_int_x1 = convert_df_lista_int(df['xmin'][i])\n",
    "    lista_int_x2 = convert_df_lista_int(df['xmax'][i])\n",
    "    lista_int_y1 = convert_df_lista_int(df['ymin'][i])\n",
    "    lista_int_y2 = convert_df_lista_int(df['ymax'][i])\n",
    "    \n",
    "            \n",
    "    # se a classe for covid, salvará como 0 (0 = covid)\n",
    "    if df['class_name'][i] == 'covid':\n",
    "        for j in range(len(lista_int_x1)):\n",
    "            bb = [lista_int_x1[j], lista_int_y1[j], lista_int_x2[j], lista_int_y2[j]]\n",
    "            #print(bb)\n",
    "            result = (convert(str(bb)).replace(',', '')) # transforma a lista em string\n",
    "            file.write('0 ' + result + '\\n') # salva no txt    \n",
    "    elif df['class_name'][i] == 'normal':\n",
    "        result = (convert(str(bb)).replace(',', '')) # transforma a lista em string\n",
    "        file.write('1 ' + result + '\\n') # salva no txt    \n",
    "    file.close() # fecha o txt\n",
    "#     file2.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a98398",
   "metadata": {},
   "source": [
    "#### Create files -> Pred (Yolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b02c7ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera os txt (vazio) que não foram preditos nada para que não haja diferença de quantidade entre o GT e o pred\n",
    "\n",
    "path_labels_pred = '/home/karem/Artigo_Periodico/Detector/Ensemble/labels/2detectors/'\n",
    "\n",
    "for i in range(len(df)):\n",
    "    \n",
    "    # cria um txt com os nomes das imagens\n",
    "    # substitui o .png do dataframe para txt\n",
    "    nome_file = os.path.basename(df.iloc[i,0].replace('_image', '.txt'))\n",
    "    \n",
    "    # cria o arquivo txt no modo escrita (w)\n",
    "    #file = open(path_labelsGT + nome_file, \"w\") \n",
    "    if not (os.path.exists(path_labels_pred + nome_file)): # se o arquivo txt não existir (se a yolo não gerou label)\n",
    "        print(nome_file)\n",
    "        file2 = open(path_labels_pred + nome_file, \"w\")\n",
    "        file2.write('1 1 0 0 0 0') # salva no txt       \n",
    "    \n",
    "        file2.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb0352",
   "metadata": {},
   "source": [
    "## Non max Supression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03c6e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria o dietório caso não exista\n",
    "def create_folders(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "        \n",
    "# se houver a pasta, ela é removida\n",
    "import shutil\n",
    "def remove_folders(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "        \n",
    "        \n",
    "# Convert lista para string\n",
    "def convert2(lst):    \n",
    "    return ' '.join(lst)\n",
    "\n",
    "\n",
    "import re\n",
    "# Convert lista para string\n",
    "def convert(lst):\n",
    "    #i = ''.join(lst)\n",
    "    i = \" \".join(lst.split())\n",
    "    str1 = re.sub(r\"[\\([{})\\]]\", \"\", i)\n",
    "    str1 = \" \".join(str1.split())\n",
    "    return str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a50fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_labels_yolo = '/home/karem/Artigo_Periodico/Detector/Ensemble/labels/2detectors/*.txt'\n",
    "\n",
    "path_labels_pred = '/home/karem/Artigo_Periodico/Detector/Ensemble/labels/2detectors_pred_final/'\n",
    "\n",
    "val_thres = 0.5 #NMS\n",
    "remove_folders(path_labels_pred)\n",
    "create_folders(path_labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "079ccfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pytorch and confidence score\n",
    "#https://learnopencv.com/non-maximum-suppression-theory-and-implementation-in-pytorch/\n",
    "\n",
    "# use y2 \n",
    "#https://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/\n",
    "\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    # initialize the list of picked indexes\n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,2]\n",
    "    y1 = boxes[:,3]\n",
    "    x2 = boxes[:,4]\n",
    "    y2 = boxes[:,5]\n",
    "    \n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    #idxs = np.argsort(y2)\n",
    "    \n",
    "    ## confidence score besides y-coordinate\n",
    "    conf = boxes[:,1]\n",
    "    idxs = np.argsort(conf)\n",
    "    \n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "                                               np.where(overlap > overlapThresh)[0])))\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    \n",
    "    return boxes[pick].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f2efd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 564/564 [00:00<00:00, 3255.69it/s]\n"
     ]
    }
   ],
   "source": [
    "for file_path in tqdm(glob(path_labels_yolo)):    \n",
    "    image_id = file_path.split('/')[-1].split('.')[0] + '_image'\n",
    "    \n",
    "    #print(image_id)\n",
    "    f = open(file_path, 'r')   \n",
    "    #print(file_path)\n",
    "    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n",
    "        \n",
    "    data[:,1] = data[:,1] * 100\n",
    "    \n",
    "    \n",
    "    new_data = non_max_suppression_fast(data, val_thres)\n",
    "    \n",
    "    nome_file = os.path.basename(file_path)\n",
    "    file = open(path_labels_pred + nome_file, \"w\")  \n",
    "    for idx in range(len(new_data)):\n",
    "        result = convert(str(new_data[idx]))\n",
    "    \n",
    "        for i in range(0,100):\n",
    "            result = result.replace(' ' + str(i) + ' ', ' 0.' + str(i) + ' ')\n",
    "\n",
    "        file.write(result + '\\n')\n",
    "    file.close() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc31149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################\n",
    "# # Usar essa parte no caso de faltar GT (Classificação antecedendo a Detecção)\n",
    "# ##################################################\n",
    "\n",
    "# for file_path in tqdm(glob(path_labels_pred)):    \n",
    "#     image_id = file_path.split('/')[-1].split('.')[0] + '.txt'\n",
    "    \n",
    "#     if not(os.path.exists(path_labelsGT + image_id)):\n",
    "#         file = open(path_labelsGT + image_id, \"w\")  \n",
    "#         file.write('0 0 0 0 0\\n')\n",
    "#         file.close()\n",
    "        \n",
    "#         print(image_id)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bf193c",
   "metadata": {},
   "source": [
    "## mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5e3d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import operator\n",
    "import sys\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cafa76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_average_miss_rate(prec, rec, num_images):\n",
    "    \"\"\"\n",
    "        log-average miss rate:\n",
    "            Calculated by averaging miss rates at 9 evenly spaced FPPI points\n",
    "            between 10e-2 and 10e0, in log-space.\n",
    "\n",
    "        output:\n",
    "                lamr | log-average miss rate\n",
    "                mr | miss rate\n",
    "                fppi | false positives per image\n",
    "\n",
    "        references:\n",
    "            [1] Dollar, Piotr, et al. \"Pedestrian Detection: An Evaluation of the\n",
    "               State of the Art.\" Pattern Analysis and Machine Intelligence, IEEE\n",
    "               Transactions on 34.4 (2012): 743 - 761.\n",
    "    \"\"\"\n",
    "\n",
    "    # if there were no detections of that class\n",
    "    if prec.size == 0:\n",
    "        lamr = 0\n",
    "        mr = 1\n",
    "        fppi = 0\n",
    "        return lamr, mr, fppi\n",
    "\n",
    "    fppi = (1 - prec)\n",
    "    mr = (1 - rec)\n",
    "\n",
    "    fppi_tmp = np.insert(fppi, 0, -1.0)\n",
    "    mr_tmp = np.insert(mr, 0, 1.0)\n",
    "\n",
    "    # Use 9 evenly spaced reference points in log-space\n",
    "    ref = np.logspace(-2.0, 0.0, num = 9)\n",
    "    for i, ref_i in enumerate(ref):\n",
    "        # np.where() will always find at least 1 index, since min(ref) = 0.01 and min(fppi_tmp) = -1.0\n",
    "        j = np.where(fppi_tmp <= ref_i)[-1][-1]\n",
    "        ref[i] = mr_tmp[j]\n",
    "\n",
    "    # log(0) is undefined, so we use the np.maximum(1e-10, ref)\n",
    "    lamr = math.exp(np.mean(np.log(np.maximum(1e-10, ref))))\n",
    "\n",
    "    return lamr, mr, fppi\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    " throw error and exit\n",
    "\"\"\"\n",
    "def error(msg):\n",
    "    print(msg)\n",
    "    sys.exit(0)\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    " check if the number is a float between 0.0 and 1.0\n",
    "\"\"\"\n",
    "def is_float_between_0_and_1(value):\n",
    "    try:\n",
    "        val = float(value)\n",
    "        if val > 0.0 and val < 1.0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except ValueError:\n",
    "        return False\n",
    "#####################################################################################################################################\n",
    "\"\"\"\n",
    " Calculate the AP given the recall and precision array\n",
    "    1st) We compute a version of the measured precision/recall curve with\n",
    "         precision monotonically decreasing\n",
    "    2nd) We compute the AP as the area under this curve by numerical integration.\n",
    "\"\"\"\n",
    "def voc_ap(rec, prec):\n",
    "    \"\"\"\n",
    "    --- Official matlab code VOC2012---\n",
    "    mrec=[0 ; rec ; 1];\n",
    "    mpre=[0 ; prec ; 0];\n",
    "    for i=numel(mpre)-1:-1:1\n",
    "            mpre(i)=max(mpre(i),mpre(i+1));\n",
    "    end\n",
    "    i=find(mrec(2:end)~=mrec(1:end-1))+1;\n",
    "    ap=sum((mrec(i)-mrec(i-1)).*mpre(i));\n",
    "    \"\"\"\n",
    "    rec.insert(0, 0.0) # insert 0.0 at begining of list\n",
    "    rec.append(1.0) # insert 1.0 at end of list\n",
    "    mrec = rec[:]\n",
    "    prec.insert(0, 0.0) # insert 0.0 at begining of list\n",
    "    prec.append(0.0) # insert 0.0 at end of list\n",
    "    mpre = prec[:]\n",
    "    \"\"\"\n",
    "     This part makes the precision monotonically decreasing\n",
    "        (goes from the end to the beginning)\n",
    "        matlab: for i=numel(mpre)-1:-1:1\n",
    "                    mpre(i)=max(mpre(i),mpre(i+1));\n",
    "    \"\"\"\n",
    "    # matlab indexes start in 1 but python in 0, so I have to do:\n",
    "    #     range(start=(len(mpre) - 2), end=0, step=-1)\n",
    "    # also the python function range excludes the end, resulting in:\n",
    "    #     range(start=(len(mpre) - 2), end=-1, step=-1)\n",
    "    for i in range(len(mpre)-2, -1, -1):\n",
    "        mpre[i] = max(mpre[i], mpre[i+1])\n",
    "    \"\"\"\n",
    "     This part creates a list of indexes where the recall changes\n",
    "        matlab: i=find(mrec(2:end)~=mrec(1:end-1))+1;\n",
    "    \"\"\"\n",
    "    i_list = []\n",
    "    for i in range(1, len(mrec)):\n",
    "        if mrec[i] != mrec[i-1]:\n",
    "            i_list.append(i) # if it was matlab would be i + 1\n",
    "    \"\"\"\n",
    "     The Average Precision (AP) is the area under the curve\n",
    "        (numerical integration)\n",
    "        matlab: ap=sum((mrec(i)-mrec(i-1)).*mpre(i));\n",
    "    \"\"\"\n",
    "    ap = 0.0\n",
    "    for i in i_list:\n",
    "        ap += ((mrec[i]-mrec[i-1])*mpre[i])\n",
    "    return ap, mrec, mpre\n",
    "\n",
    "\n",
    "\"\"\"\n",
    " Convert the lines of a file to a list\n",
    "\"\"\"\n",
    "def file_lines_to_list(path):\n",
    "    # open txt file lines to a list\n",
    "    with open(path) as f:\n",
    "        content = f.readlines()\n",
    "    # remove whitespace characters like `\\n` at the end of each line\n",
    "    content = [x.strip() for x in content]\n",
    "    return content\n",
    "\n",
    "\n",
    "\"\"\"\n",
    " Plot - adjust axes\n",
    "\"\"\"\n",
    "def adjust_axes(r, t, fig, axes):\n",
    "    # get text width for re-scaling\n",
    "    bb = t.get_window_extent(renderer=r)\n",
    "    text_width_inches = bb.width / fig.dpi\n",
    "    # get axis width in inches\n",
    "    current_fig_width = fig.get_figwidth()\n",
    "    new_fig_width = current_fig_width + text_width_inches\n",
    "    propotion = new_fig_width / current_fig_width\n",
    "    # get axis limit\n",
    "    x_lim = axes.get_xlim()\n",
    "    axes.set_xlim([x_lim[0], x_lim[1]*propotion])\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    " Draw plot using Matplotlib\n",
    "\"\"\"\n",
    "def draw_plot_func(dictionary, n_classes, window_title, plot_title, x_label, output_path, to_show, plot_color, true_p_bar):\n",
    "    # sort the dictionary by decreasing value, into a list of tuples\n",
    "    sorted_dic_by_value = sorted(dictionary.items(), key=operator.itemgetter(1))\n",
    "    # unpacking the list of tuples into two lists\n",
    "    sorted_keys, sorted_values = zip(*sorted_dic_by_value)\n",
    "    #   \n",
    "    \n",
    "    if true_p_bar != \"\":\n",
    "        \"\"\"\n",
    "         Special case to draw in:\n",
    "            - green -> TP: True Positives (object detected and matches ground-truth)\n",
    "            - red -> FP: False Positives (object detected but does not match ground-truth)\n",
    "            - pink -> FN: False Negatives (object not detected but present in the ground-truth)\n",
    "        \"\"\"\n",
    "        fp_sorted = []\n",
    "        tp_sorted = []\n",
    "        for key in sorted_keys:\n",
    "            fp_sorted.append(dictionary[key] - true_p_bar[key])\n",
    "            tp_sorted.append(true_p_bar[key])\n",
    "        plt.barh(range(n_classes), fp_sorted, align='center', color='crimson', label='False Positive')\n",
    "        plt.barh(range(n_classes), tp_sorted, align='center', color='forestgreen', label='True Positive', left=fp_sorted)\n",
    "        # add legend\n",
    "        plt.legend(loc='lower right')\n",
    "        \"\"\"\n",
    "         Write number on side of bar\n",
    "        \"\"\"\n",
    "        fig = plt.gcf() # gcf - get current figure\n",
    "        axes = plt.gca()\n",
    "        r = fig.canvas.get_renderer()\n",
    "        for i, val in enumerate(sorted_values):\n",
    "            fp_val = fp_sorted[i]\n",
    "            tp_val = tp_sorted[i]\n",
    "            fp_str_val = \" \" + str(fp_val)\n",
    "            tp_str_val = fp_str_val + \" \" + str(tp_val)\n",
    "            # trick to paint multicolor with offset:\n",
    "            # first paint everything and then repaint the first number\n",
    "            t = plt.text(val, i, tp_str_val, color='forestgreen', va='center', fontweight='bold')\n",
    "            plt.text(val, i, fp_str_val, color='crimson', va='center', fontweight='bold')\n",
    "            if i == (len(sorted_values)-1): # largest bar\n",
    "                adjust_axes(r, t, fig, axes)\n",
    "    else:\n",
    "        plt.barh(range(n_classes), sorted_values, color=plot_color)\n",
    "        \"\"\"\n",
    "         Write number on side of bar\n",
    "        \"\"\"\n",
    "        fig = plt.gcf() # gcf - get current figure\n",
    "        axes = plt.gca()\n",
    "        r = fig.canvas.get_renderer()\n",
    "        for i, val in enumerate(sorted_values):\n",
    "            str_val = \" \" + str(val) # add a space before\n",
    "            if val < 1.0:\n",
    "                str_val = \" {0:.2f}\".format(val)\n",
    "            t = plt.text(val, i, str_val, color=plot_color, va='center', fontweight='bold')\n",
    "            # re-set axes to show number inside the figure\n",
    "            if i == (len(sorted_values)-1): # largest bar\n",
    "                adjust_axes(r, t, fig, axes)\n",
    "    # set window title\n",
    "    fig.canvas.set_window_title(window_title)\n",
    "    # write classes in y axis\n",
    "    tick_font_size = 12\n",
    "    plt.yticks(range(n_classes), sorted_keys, fontsize=tick_font_size)\n",
    "    \"\"\"\n",
    "     Re-scale height accordingly\n",
    "    \"\"\"\n",
    "    init_height = fig.get_figheight()\n",
    "    # comput the matrix height in points and inches\n",
    "    dpi = fig.dpi\n",
    "    height_pt = n_classes * (tick_font_size * 1.4) # 1.4 (some spacing)\n",
    "    height_in = height_pt / dpi\n",
    "    # compute the required figure height \n",
    "    top_margin = 0.15 # in percentage of the figure height\n",
    "    bottom_margin = 0.05 # in percentage of the figure height\n",
    "    figure_height = height_in / (1 - top_margin - bottom_margin)\n",
    "    # set new height\n",
    "    if figure_height > init_height:\n",
    "        fig.set_figheight(figure_height)\n",
    "\n",
    "    # set plot title\n",
    "    plt.title(plot_title, fontsize=14)\n",
    "    # set axis titles\n",
    "    # plt.xlabel('classes')\n",
    "    plt.xlabel(x_label, fontsize='large')\n",
    "    # adjust size of window\n",
    "    fig.tight_layout()\n",
    "    # save the plot\n",
    "    fig.savefig(output_path)\n",
    "    # show image\n",
    "    if to_show:\n",
    "        plt.show()\n",
    "    # close the plot\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00b9d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################################\n",
    "#####################################################################################################################################\n",
    "#####################################################################################################################################\n",
    "#####################################################################################################################################\n",
    "#####################################################################################################################################\n",
    "#####################################################################################################################################\n",
    "#####################################################################################################################################\n",
    "#####################################################################################################################################\n",
    "#####################################################################################################################################\n",
    "\n",
    "MINOVERLAP = 0.45 # default value (defined in the PASCAL VOC2012 challenge)\n",
    "# MINOVERLAP = 0.5 # default value (defined in the PASCAL VOC2012 challenge)\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-na', '--no-animation', help=\"no animation is shown.\", action=\"store_true\")\n",
    "parser.add_argument('-np', '--no-plot', help=\"no plot is shown.\", action=\"store_true\")\n",
    "parser.add_argument('-q', '--quiet', help=\"minimalistic console output.\", action=\"store_true\")\n",
    "# argparse receiving list of classes to be ignored (e.g., python main.py --ignore person book)\n",
    "parser.add_argument('-i', '--ignore', nargs='+', type=str, help=\"ignore a list of classes.\")\n",
    "# argparse receiving list of classes with specific IoU (e.g., python main.py --set-class-iou person 0.7)\n",
    "parser.add_argument('--set-class-iou', nargs='+', type=str, help=\"set IoU for a specific class.\")\n",
    "sys.argv = ['-f']\n",
    "args = parser.parse_args()\n",
    "\n",
    "#https://sungwookyoo.github.io/tips/ArgParser/\n",
    "#args = vars(parser.parse_args())\n",
    "\n",
    "\n",
    "\n",
    "# pal_chave_peso = \"ensaio\"\n",
    "# epoca          = 69 \n",
    "# rede           = 'Mask_rcnn'\n",
    "# path_input = 'd:/usuarios/diego.cardona/Desktop/Mis programas/mAP-master-YO/input/' \n",
    "# path_ouput = path_input + '/output_maP_'+rede+'/'\n",
    "# GT_PATH = os.path.join( path_input, 'ground-truth')\n",
    "# DR_PATH = os.path.join( path_input, 'detection-results')\n",
    "\n",
    "rede = 'ensemble'\n",
    "#path_input = '/home/karem/Artigo_SPIE_Kaggle/YoloEvaluation/labels/'\n",
    "#path_ouput = path_input + '/output_maP_' + rede + '/'\n",
    "#GT_PATH = os.path.join( path_input, 'true_yolo')\n",
    "#DR_PATH = os.path.join( path_input, 'pred_yolo')\n",
    "\n",
    "path_input = '/home/karem/Artigo_Periodico/Detector/Ensemble/labels/'\n",
    "path_ouput = path_input + '/output_maP_' + rede + '/'\n",
    "GT_PATH = os.path.join(path_input, 'ground_truth')\n",
    "#GT_PATH = os.path.join(path_input)\n",
    "DR_PATH = os.path.join(path_input, '2detectors_pred_final')\n",
    "\n",
    "            \n",
    "'''\n",
    "    0,0 ------> x (width)\n",
    "     |\n",
    "     |  (Left,Top)\n",
    "     |      *_________\n",
    "     |      |         |\n",
    "            |         |\n",
    "     y      |_________|\n",
    "  (height)            *\n",
    "                (Right,Bottom)\n",
    "'''\n",
    "\n",
    "# if there are no classes to ignore then replace None by empty list\n",
    "if args.ignore is None:\n",
    "    args.ignore = []\n",
    "\n",
    "specific_iou_flagged = False\n",
    "if args.set_class_iou is not None:\n",
    "    specific_iou_flagged = True\n",
    "\n",
    "# make sure that the cwd() is the location of the python script (so that every path makes sense)\n",
    "#os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "\n",
    "# GT_PATH = os.path.join( path_input, 'true_mask_rcnn')\n",
    "# DR_PATH = os.path.join( path_input, 'pred_mask_rcnn')\n",
    "\n",
    "# if there are no images then no animation can be shown\n",
    "args.no_animation = True\n",
    "\n",
    "\n",
    "# try to import Matplotlib if the user didn't choose the option --no-plot\n",
    "draw_plot = False\n",
    "if not args.no_plot:\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        draw_plot = True\n",
    "    except ImportError:\n",
    "        print(\"\\\"matplotlib\\\" not found, please install it to get the resulting plots.\")\n",
    "        args.no_plot = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7dfeb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Create a \".temp_files/\" and \"output/\" directory\n",
    "\"\"\"\n",
    "\n",
    "#draw_plot = False\n",
    "\n",
    "TEMP_FILES_PATH = \".temp_files\"\n",
    "if not os.path.exists(TEMP_FILES_PATH): # if it doesn't exist already\n",
    "    os.makedirs(TEMP_FILES_PATH)\n",
    "    \n",
    "\n",
    "if os.path.exists(path_ouput): # if it exist already\n",
    "    # reset the output directory\n",
    "    shutil.rmtree(path_ouput)\n",
    "\n",
    "os.makedirs(path_ouput)\n",
    "if draw_plot:\n",
    "    os.makedirs(os.path.join(path_ouput, \"classes\"))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    " ground-truth\n",
    "     Load each of the ground-truth files into a temporary \".json\" file.\n",
    "     Create a list of all the class names present in the ground-truth (gt_classes).\n",
    "\"\"\"\n",
    "# get a list with the ground-truth files\n",
    "ground_truth_files_list = glob.glob(GT_PATH + '/*.txt')\n",
    "if len(ground_truth_files_list) == 0:\n",
    "    error(\"Error: No ground-truth files found!\")\n",
    "ground_truth_files_list.sort()\n",
    "# dictionary with counter per class\n",
    "gt_counter_per_class = {}\n",
    "counter_images_per_class = {}\n",
    "\n",
    "gt_files = []\n",
    "for txt_file in ground_truth_files_list:\n",
    "    #print(txt_file)\n",
    "    file_id = txt_file.split(\".txt\", 1)[0]\n",
    "    file_id = os.path.basename(os.path.normpath(file_id))\n",
    "    # check if there is a correspondent detection-results file\n",
    "    temp_path = os.path.join(DR_PATH, (file_id + \".txt\"))\n",
    "    if not os.path.exists(temp_path):\n",
    "        error_msg = \"Error. File not found: {}\\n\".format(temp_path)\n",
    "        error_msg += \"(You can avoid this error message by running extra/intersect-gt-and-dr.py)\"\n",
    "        error(error_msg)\n",
    "    lines_list = file_lines_to_list(txt_file)\n",
    "    # create ground-truth dictionary\n",
    "    bounding_boxes = []\n",
    "    is_difficult = False\n",
    "    already_seen_classes = []\n",
    "    for line in lines_list:\n",
    "        try:\n",
    "            if \"difficult\" in line:\n",
    "                    class_name, left, top, right, bottom, _difficult = line.split()\n",
    "                    is_difficult = True\n",
    "            else:\n",
    "                    class_name, left, top, right, bottom = line.split()\n",
    "        except ValueError:\n",
    "            error_msg = \"Error: File \" + txt_file + \" in the wrong format.\\n\"\n",
    "            error_msg += \" Expected: <class_name> <left> <top> <right> <bottom> ['difficult']\\n\"\n",
    "            error_msg += \" Received: \" + line\n",
    "            error_msg += \"\\n\\nIf you have a <class_name> with spaces between words you should remove them\\n\"\n",
    "            error_msg += \"by running the script \\\"remove_space.py\\\" or \\\"rename_class.py\\\" in the \\\"extra/\\\" folder.\"\n",
    "            error(error_msg)\n",
    "        # check if class is in the ignore list, if yes skip\n",
    "        if class_name in args.ignore:\n",
    "            continue\n",
    "        bbox = left + \" \" + top + \" \" + right + \" \" +bottom\n",
    "        if is_difficult:\n",
    "            bounding_boxes.append({\"class_name\":class_name, \"bbox\":bbox, \"used\":False, \"difficult\":True})\n",
    "            is_difficult = False\n",
    "        else:\n",
    "            bounding_boxes.append({\"class_name\":class_name, \"bbox\":bbox, \"used\":False})\n",
    "            # count that object\n",
    "            if class_name in gt_counter_per_class:\n",
    "                gt_counter_per_class[class_name] += 1\n",
    "            else:\n",
    "                # if class didn't exist yet\n",
    "                gt_counter_per_class[class_name] = 1\n",
    "\n",
    "            if class_name not in already_seen_classes:\n",
    "                if class_name in counter_images_per_class:\n",
    "                    counter_images_per_class[class_name] += 1\n",
    "                else:\n",
    "                    # if class didn't exist yet\n",
    "                    counter_images_per_class[class_name] = 1\n",
    "                already_seen_classes.append(class_name)\n",
    "\n",
    "\n",
    "    # dump bounding_boxes into a \".json\" file\n",
    "    new_temp_file = TEMP_FILES_PATH + \"/\" + file_id + \"_ground_truth.json\"\n",
    "    gt_files.append(new_temp_file)\n",
    "    with open(new_temp_file, 'w') as outfile:\n",
    "        json.dump(bounding_boxes, outfile)\n",
    "\n",
    "gt_classes = list(gt_counter_per_class.keys())\n",
    "# let's sort the classes alphabetically\n",
    "gt_classes = sorted(gt_classes)\n",
    "n_classes = len(gt_classes)\n",
    "#print(gt_classes)\n",
    "#print(gt_counter_per_class)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    " Check format of the flag --set-class-iou (if used)\n",
    "    e.g. check if class exists\n",
    "\"\"\"\n",
    "if specific_iou_flagged:\n",
    "    n_args = len(args.set_class_iou)\n",
    "    error_msg = \\\n",
    "        '\\n --set-class-iou [class_1] [IoU_1] [class_2] [IoU_2] [...]'\n",
    "    if n_args % 2 != 0:\n",
    "        error('Error, missing arguments. Flag usage:' + error_msg)\n",
    "    # [class_1] [IoU_1] [class_2] [IoU_2]\n",
    "    # specific_iou_classes = ['class_1', 'class_2']\n",
    "    specific_iou_classes = args.set_class_iou[::2] # even\n",
    "    # iou_list = ['IoU_1', 'IoU_2']\n",
    "    iou_list = args.set_class_iou[1::2] # odd\n",
    "    if len(specific_iou_classes) != len(iou_list):\n",
    "        error('Error, missing arguments. Flag usage:' + error_msg)\n",
    "    for tmp_class in specific_iou_classes:\n",
    "        if tmp_class not in gt_classes:\n",
    "                    error('Error, unknown class \\\"' + tmp_class + '\\\". Flag usage:' + error_msg)\n",
    "    for num in iou_list:\n",
    "        if not is_float_between_0_and_1(num):\n",
    "            error('Error, IoU must be between 0.0 and 1.0. Flag usage:' + error_msg)\n",
    "\n",
    "            \n",
    "            \n",
    "\"\"\"\n",
    " detection-results\n",
    "     Load each of the detection-results files into a temporary \".json\" file.\n",
    "\"\"\"\n",
    "# get a list with the detection-results files\n",
    "dr_files_list = glob.glob(DR_PATH + '/*.txt')\n",
    "dr_files_list.sort()\n",
    "\n",
    "for class_index, class_name in enumerate(gt_classes):\n",
    "    bounding_boxes = []\n",
    "    for txt_file in dr_files_list:\n",
    "        #print(txt_file)\n",
    "        # the first time it checks if all the corresponding ground-truth files exist\n",
    "        file_id = txt_file.split(\".txt\",1)[0]\n",
    "        file_id = os.path.basename(os.path.normpath(file_id))\n",
    "        temp_path = os.path.join(GT_PATH, (file_id + \".txt\"))\n",
    "        if class_index == 0:\n",
    "            if not os.path.exists(temp_path):\n",
    "                error_msg = \"Error. File not found: {}\\n\".format(temp_path)\n",
    "                error_msg += \"(You can avoid this error message by running extra/intersect-gt-and-dr.py)\"\n",
    "                error(error_msg)\n",
    "        lines = file_lines_to_list(txt_file)\n",
    "        for line in lines:\n",
    "            try:\n",
    "                tmp_class_name, confidence, left, top, right, bottom = line.split()\n",
    "            except ValueError:\n",
    "                error_msg = \"Error: File \" + txt_file + \" in the wrong format.\\n\"\n",
    "                error_msg += \" Expected: <class_name> <confidence> <left> <top> <right> <bottom>\\n\"\n",
    "                error_msg += \" Received: \" + line\n",
    "                error(error_msg)\n",
    "            if tmp_class_name == class_name:\n",
    "                #print(\"match\")\n",
    "                bbox = left + \" \" + top + \" \" + right + \" \" +bottom\n",
    "                bounding_boxes.append({\"confidence\":confidence, \"file_id\":file_id, \"bbox\":bbox})\n",
    "                #print(bounding_boxes)\n",
    "    # sort detection-results by decreasing confidence\n",
    "    bounding_boxes.sort(key=lambda x:float(x['confidence']), reverse=True)\n",
    "    with open(TEMP_FILES_PATH + \"/\" + class_name + \"_dr.json\", 'w') as outfile:\n",
    "        json.dump(bounding_boxes, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "736a2c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.53% = 0 AP \n",
      "0.00% = 1 AP \n",
      "mAP = 17.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47034/18172192.py:128: MatplotlibDeprecationWarning: \n",
      "The set_window_title function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use manager.set_window_title or GUI-specific methods instead.\n",
      "  fig.canvas.set_window_title('AP ' + class_name)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    " Calculate the AP for each class\n",
    "\"\"\"\n",
    "sum_AP = 0.0\n",
    "ap_dictionary = {}\n",
    "lamr_dictionary = {}\n",
    "# open file to store the output\n",
    "with open(path_ouput + \"/output.txt\", 'w') as output_file:\n",
    "    output_file.write(\"# AP and precision/recall per class\\n\")\n",
    "    count_true_positives = {}\n",
    "    for class_index, class_name in enumerate(gt_classes):\n",
    "        count_true_positives[class_name] = 0\n",
    "        \"\"\"\n",
    "         Load detection-results of that class\n",
    "        \"\"\"\n",
    "        dr_file = TEMP_FILES_PATH + \"/\" + class_name + \"_dr.json\"\n",
    "        dr_data = json.load(open(dr_file))\n",
    "\n",
    "        \"\"\"\n",
    "         Assign detection-results to ground-truth objects\n",
    "        \"\"\"\n",
    "        nd = len(dr_data)\n",
    "        tp = [0] * nd # creates an array of zeros of size nd\n",
    "        fp = [0] * nd\n",
    "        for idx, detection in enumerate(dr_data):\n",
    "            file_id = detection[\"file_id\"]\n",
    "            \n",
    "            # assign detection-results to ground truth object if any\n",
    "            # open ground-truth with that file_id\n",
    "            gt_file = TEMP_FILES_PATH + \"/\" + file_id + \"_ground_truth.json\"\n",
    "            ground_truth_data = json.load(open(gt_file))\n",
    "            ovmax = -1\n",
    "            gt_match = -1\n",
    "            # load detected object bounding-box\n",
    "            bb = [ float(x) for x in detection[\"bbox\"].split() ]\n",
    "            for obj in ground_truth_data:\n",
    "                # look for a class_name match\n",
    "                if obj[\"class_name\"] == class_name:\n",
    "                    bbgt = [ float(x) for x in obj[\"bbox\"].split() ]\n",
    "                    bi = [max(bb[0],bbgt[0]), max(bb[1],bbgt[1]), min(bb[2],bbgt[2]), min(bb[3],bbgt[3])]\n",
    "                    iw = bi[2] - bi[0] + 1\n",
    "                    ih = bi[3] - bi[1] + 1\n",
    "                    if iw > 0 and ih > 0:\n",
    "                        # compute overlap (IoU) = area of intersection / area of union\n",
    "                        ua = (bb[2] - bb[0] + 1) * (bb[3] - bb[1] + 1) + (bbgt[2] - bbgt[0]\n",
    "                                        + 1) * (bbgt[3] - bbgt[1] + 1) - iw * ih\n",
    "                        ov = iw * ih / ua\n",
    "                        if ov > ovmax:\n",
    "                            ovmax = ov\n",
    "                            gt_match = obj\n",
    "\n",
    "            # assign detection as true positive/don't care/false positive\n",
    "            # set minimum overlap\n",
    "            min_overlap = MINOVERLAP\n",
    "            if specific_iou_flagged:\n",
    "                if class_name in specific_iou_classes:\n",
    "                    index = specific_iou_classes.index(class_name)\n",
    "                    min_overlap = float(iou_list[index])\n",
    "            if ovmax >= min_overlap:\n",
    "                if \"difficult\" not in gt_match:\n",
    "                        if not bool(gt_match[\"used\"]):\n",
    "                            # true positive\n",
    "                            tp[idx] = 1\n",
    "                            gt_match[\"used\"] = True\n",
    "                            count_true_positives[class_name] += 1\n",
    "                            # update the \".json\" file\n",
    "                            with open(gt_file, 'w') as f:\n",
    "                                    f.write(json.dumps(ground_truth_data))\n",
    "                        else:\n",
    "                            # false positive (multiple detection)\n",
    "                            fp[idx] = 1\n",
    "\n",
    "            else:\n",
    "                # false positive\n",
    "                fp[idx] = 1\n",
    "                if ovmax > 0:\n",
    "                    status = \"INSUFFICIENT OVERLAP\"\n",
    "\n",
    "        #print(tp)\n",
    "        # compute precision/recall\n",
    "        cumsum = 0\n",
    "        for idx, val in enumerate(fp):\n",
    "            fp[idx] += cumsum\n",
    "            cumsum += val\n",
    "        cumsum = 0\n",
    "        for idx, val in enumerate(tp):\n",
    "            tp[idx] += cumsum\n",
    "            cumsum += val\n",
    "        #print(tp)\n",
    "        rec = tp[:]\n",
    "        for idx, val in enumerate(tp):\n",
    "            rec[idx] = float(tp[idx]) / gt_counter_per_class[class_name]\n",
    "        #print(rec)\n",
    "        prec = tp[:]\n",
    "        for idx, val in enumerate(tp):\n",
    "            prec[idx] = float(tp[idx]) / (fp[idx] + tp[idx])\n",
    "        #print(prec)\n",
    "\n",
    "        ap, mrec, mprec = voc_ap(rec[:], prec[:])\n",
    "        sum_AP += ap\n",
    "        text = \"{0:.2f}%\".format(ap*100) + \" = \" + class_name + \" AP \" #class_name + \" AP = {0:.2f}%\".format(ap*100)\n",
    "        \"\"\"\n",
    "         Write to output.txt\n",
    "        \"\"\"\n",
    "        rounded_prec = [ '%.2f' % elem for elem in prec ]\n",
    "        rounded_rec = [ '%.2f' % elem for elem in rec ]\n",
    "        output_file.write(text + \"\\n Precision: \" + str(rounded_prec) + \"\\n Recall :\" + str(rounded_rec) + \"\\n\\n\")\n",
    "        if not args.quiet:\n",
    "            print(text)\n",
    "        ap_dictionary[class_name] = ap\n",
    "\n",
    "        n_images = counter_images_per_class[class_name]\n",
    "        lamr, mr, fppi = log_average_miss_rate(np.array(prec), np.array(rec), n_images)\n",
    "        lamr_dictionary[class_name] = lamr\n",
    "\n",
    "        \"\"\"\n",
    "         Draw plot\n",
    "        \"\"\"\n",
    "        if draw_plot:\n",
    "            plt.plot(rec, prec, '-o')\n",
    "            # add a new penultimate point to the list (mrec[-2], 0.0)\n",
    "            # since the last line segment (and respective area) do not affect the AP value\n",
    "            area_under_curve_x = mrec[:-1] + [mrec[-2]] + [mrec[-1]]\n",
    "            area_under_curve_y = mprec[:-1] + [0.0] + [mprec[-1]]\n",
    "            plt.fill_between(area_under_curve_x, 0, area_under_curve_y, alpha=0.2, edgecolor='r')\n",
    "            # set window title\n",
    "            fig = plt.gcf() # gcf - get current figure\n",
    "            fig.canvas.set_window_title('AP ' + class_name)\n",
    "            # set plot title\n",
    "            plt.title('class: ' + text)\n",
    "            #plt.suptitle('This is a somewhat long figure title', fontsize=16)\n",
    "            # set axis titles\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            # optional - set axes\n",
    "            axes = plt.gca() # gca - get current axes\n",
    "            axes.set_xlim([0.0,1.0])\n",
    "            axes.set_ylim([0.0,1.05]) # .05 to give some extra space\n",
    "            # Alternative option -> wait for button to be pressed\n",
    "            #while not plt.waitforbuttonpress(): pass # wait for key display\n",
    "            # Alternative option -> normal display\n",
    "            #plt.show()\n",
    "            # save the plot\n",
    "            fig.savefig(path_ouput + \"/classes/\" + class_name + \".png\")\n",
    "            plt.cla() # clear axes for next plot\n",
    "\n",
    "\n",
    "    output_file.write(\"\\n# mAP of all classes\\n\")\n",
    "    mAP = sum_AP / n_classes\n",
    "    text = \"mAP = {0:.2f}%\".format(mAP*100)\n",
    "    output_file.write(text + \"\\n\")\n",
    "    print(text)\n",
    "\n",
    "# remove the temp_files directory\n",
    "shutil.rmtree(TEMP_FILES_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8b6ae74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47034/2327614893.py:209: MatplotlibDeprecationWarning: \n",
      "The set_window_title function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use manager.set_window_title or GUI-specific methods instead.\n",
      "  fig.canvas.set_window_title(window_title)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    " Count total of detection-results\n",
    "\"\"\"\n",
    "# iterate through all the files\n",
    "det_counter_per_class = {}\n",
    "for txt_file in dr_files_list:\n",
    "    # get lines to list\n",
    "    lines_list = file_lines_to_list(txt_file)\n",
    "    for line in lines_list:\n",
    "        class_name = line.split()[0]\n",
    "        # check if class is in the ignore list, if yes skip\n",
    "        if class_name in args.ignore:\n",
    "            continue\n",
    "        # count that object\n",
    "        if class_name in det_counter_per_class:\n",
    "            det_counter_per_class[class_name] += 1\n",
    "        else:\n",
    "            # if class didn't exist yet\n",
    "            det_counter_per_class[class_name] = 1\n",
    "#print(det_counter_per_class)\n",
    "dr_classes = list(det_counter_per_class.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    " Plot the total number of occurences of each class in the ground-truth\n",
    "\"\"\"\n",
    "if draw_plot:\n",
    "    window_title = \"ground-truth-info\"\n",
    "    plot_title = \"ground-truth\\n\"\n",
    "    plot_title += \"(\" + str(len(ground_truth_files_list)) + \" files and \" + str(n_classes) + \" classes)\"\n",
    "    x_label = \"Number of objects per class\"\n",
    "    output_path = path_ouput + \"/ground-truth-info.png\"\n",
    "    to_show = False\n",
    "    plot_color = 'forestgreen'\n",
    "    draw_plot_func(\n",
    "        gt_counter_per_class,\n",
    "        n_classes,\n",
    "        window_title,\n",
    "        plot_title,\n",
    "        x_label,\n",
    "        output_path,\n",
    "        to_show,\n",
    "        plot_color,\n",
    "        '',\n",
    "        )\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    " Write number of ground-truth objects per class to results.txt\n",
    "\"\"\"\n",
    "with open(path_ouput + \"/output.txt\", 'a') as output_file:\n",
    "    output_file.write(\"\\n# Number of ground-truth objects per class\\n\")\n",
    "    for class_name in sorted(gt_counter_per_class):\n",
    "        output_file.write(class_name + \": \" + str(gt_counter_per_class[class_name]) + \"\\n\")\n",
    "        \n",
    "        \n",
    "        \n",
    "\"\"\"\n",
    " Finish counting true positives\n",
    "\"\"\"\n",
    "for class_name in dr_classes:\n",
    "    # if class exists in detection-result but not in ground-truth then there are no true positives in that class\n",
    "    if class_name not in gt_classes:\n",
    "        count_true_positives[class_name] = 0\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\"\"\"\n",
    " Plot the total number of occurences of each class in the \"detection-results\" folder\n",
    "\"\"\"\n",
    "if draw_plot:\n",
    "    window_title = \"detection-results-info\"\n",
    "    # Plot title\n",
    "    plot_title = \"detection-results\\n\"\n",
    "    plot_title += \"(\" + str(len(dr_files_list)) + \" files and \"\n",
    "    count_non_zero_values_in_dictionary = sum(int(x) > 0 for x in list(det_counter_per_class.values()))\n",
    "    plot_title += str(count_non_zero_values_in_dictionary) + \" detected classes)\"\n",
    "    # end Plot title\n",
    "    x_label = \"Number of objects per class\"\n",
    "    output_path = path_ouput + \"/detection-results-info.png\"\n",
    "    to_show = False\n",
    "    plot_color = 'forestgreen'\n",
    "    true_p_bar = count_true_positives\n",
    "    draw_plot_func(\n",
    "            det_counter_per_class,\n",
    "            len(det_counter_per_class),\n",
    "            window_title,\n",
    "            plot_title,\n",
    "            x_label,\n",
    "            output_path,\n",
    "            to_show,\n",
    "            plot_color,\n",
    "            true_p_bar\n",
    "        )\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    " Write number of detected objects per class to output.txt\n",
    "\"\"\"\n",
    "with open(path_ouput + \"/output.txt\", 'a') as output_file:\n",
    "    output_file.write(\"\\n# Number of detected objects per class\\n\")\n",
    "    for class_name in sorted(dr_classes):\n",
    "        n_det = det_counter_per_class[class_name]\n",
    "        text = class_name + \": \" + str(n_det)\n",
    "        text += \" (tp:\" + str(count_true_positives[class_name]) + \"\"\n",
    "        text += \", fp:\" + str(n_det - count_true_positives[class_name]) + \")\\n\"\n",
    "        output_file.write(text)\n",
    "\n",
    "        \n",
    "\"\"\"\n",
    " Draw mAP plot (Show AP's of all classes in decreasing order)\n",
    "\"\"\"\n",
    "if draw_plot:\n",
    "    window_title = \"mAP\"\n",
    "    plot_title = \"mAP = {0:.2f}%\".format(mAP*100)\n",
    "    x_label = \"Average Precision\"\n",
    "    output_path = path_ouput + \"/mAP.png\"\n",
    "    to_show = True\n",
    "    plot_color = 'royalblue'\n",
    "    draw_plot_func(\n",
    "            ap_dictionary,\n",
    "            n_classes,\n",
    "            window_title,\n",
    "            plot_title,\n",
    "            x_label,\n",
    "            output_path,\n",
    "            to_show,\n",
    "            plot_color,\n",
    "        \"\"\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ca7be4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a507c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179bcd29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
