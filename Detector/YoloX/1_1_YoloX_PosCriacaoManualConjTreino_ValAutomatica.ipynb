{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a32cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "## Instruções de uso\n",
    "#######################################################\n",
    "\n",
    "# https://www.youtube.com/watch?v=R1Bf067Z5uM&ab_channel=ArtificialImages\n",
    "# https://colab.research.google.com/drive/1gDZ2xcTOgR39tGGs-EZ6i3RTs16wmzZQ#scrollTo=1NcFxRcFdJ_O\n",
    "\n",
    "# https://www.youtube.com/watch?v=GRtgLlwxpc4&ab_channel=DeepLearning\n",
    "# https://www.makesense.ai/\n",
    "# https://www.youtube.com/watch?v=2nR2e4J4ZaI&ab_channel=KarndeepSingh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65671614",
   "metadata": {},
   "source": [
    "### Remove as pastas \n",
    "Para evitar erros, remove todas as pastas para recriá-las do zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebad4055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# se houver a pasta, ela é removida\n",
    "import shutil\n",
    "import os\n",
    "def remove_folders(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "        \n",
    "# cria o diretório caso não exista\n",
    "def createfolder(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "948606f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/karem/Artigo_Periodico/YoloX/\n"
     ]
    }
   ],
   "source": [
    "# Captura o diretório atual e salva na variável\n",
    "path_Yolo = diretorio = os.getcwd() + '/'\n",
    "print(path_Yolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08eca66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove pastas remanescentes de treinamento antigo da YoloX\n",
    "remove_folders(path_Yolo + 'apex/')\n",
    "remove_folders(path_Yolo + '/YOLOX/')\n",
    "remove_folders(path_Yolo + '/train/')\n",
    "remove_folders(path_Yolo + '/test/')\n",
    "remove_folders(path_Yolo + '/valid/')\n",
    "if os.path.exists(path_Yolo + '/yolox_s.pth'):\n",
    "    os.remove(path_Yolo + 'yolox_s.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b83de9d",
   "metadata": {},
   "source": [
    "### Início da YoloX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3794b860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'YOLOX'...\n",
      "remote: Enumerating objects: 786, done.\u001b[K\n",
      "remote: Total 786 (delta 0), reused 0 (delta 0), pack-reused 786\u001b[K\n",
      "Receiving objects: 100% (786/786), 5.78 MiB | 4.71 MiB/s, done.\n",
      "Resolving deltas: 100% (413/413), done.\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "## Install YOLOX Dependencies\n",
    "#######################################################\n",
    "\n",
    "## Instala a YoloX\n",
    "!git clone https://github.com/roboflow-ai/YOLOX.git\n",
    "\n",
    "# Muda o diretório\n",
    "# %cd YOLOX\n",
    "\n",
    "# Instala as bibliotecas (requisitos)\n",
    "# !pip3 install -U pip && pip3 install -r requirements.txt\n",
    "# !pip3 install -v -e .  \n",
    "# !pip uninstall -y torch torchvision torchaudio\n",
    "# # May need to change in the future if Colab no longer uses CUDA 11.0\n",
    "# !pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e236460a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/karem/Artigo_Periodico/YoloX\n",
      "Cloning into 'apex'...\n",
      "remote: Enumerating objects: 8256, done.\u001b[K\n",
      "remote: Counting objects: 100% (343/343), done.\u001b[K\n",
      "remote: Compressing objects: 100% (192/192), done.\u001b[K\n",
      "remote: Total 8256 (delta 204), reused 240 (delta 139), pack-reused 7913\u001b[K\n",
      "Receiving objects: 100% (8256/8256), 14.20 MiB | 7.40 MiB/s, done.\n",
      "Resolving deltas: 100% (5603/5603), done.\n",
      "/home/karem/Artigo_Periodico/YoloX/apex\n",
      "Using pip 21.2.4 from /home/karem/anaconda3/envs/env_yolox/lib/python3.7/site-packages/pip (python 3.7)\n",
      "Processing /home/karem/Artigo_Periodico/YoloX/apex\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "    Running command python setup.py egg_info\n",
      "\n",
      "\n",
      "    torch.__version__  = 1.7.1+cu110\n",
      "\n",
      "\n",
      "    running egg_info\n",
      "    creating /tmp/pip-pip-egg-info-f7rbi19q/apex.egg-info\n",
      "    writing /tmp/pip-pip-egg-info-f7rbi19q/apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to /tmp/pip-pip-egg-info-f7rbi19q/apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to /tmp/pip-pip-egg-info-f7rbi19q/apex.egg-info/top_level.txt\n",
      "    writing manifest file '/tmp/pip-pip-egg-info-f7rbi19q/apex.egg-info/SOURCES.txt'\n",
      "    reading manifest file '/tmp/pip-pip-egg-info-f7rbi19q/apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file '/tmp/pip-pip-egg-info-f7rbi19q/apex.egg-info/SOURCES.txt'\n",
      "    /tmp/pip-req-build-6alyswvh/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "Building wheels for collected packages: apex\n",
      "  Running command /home/karem/anaconda3/envs/env_yolox/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-6alyswvh/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-6alyswvh/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-_hx7yt3_\n",
      "\n",
      "\n",
      "  torch.__version__  = 1.7.1+cu110\n",
      "\n",
      "\n",
      "  /tmp/pip-req-build-6alyswvh/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "    warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib\n",
      "  creating build/lib/apex\n",
      "  copying apex/__init__.py -> build/lib/apex\n",
      "  creating build/lib/apex/pyprof\n",
      "  copying apex/pyprof/__init__.py -> build/lib/apex/pyprof\n",
      "  creating build/lib/apex/parallel\n",
      "  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/sync_batchnorm.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/LARC.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/__init__.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/distributed.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/multiproc.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib/apex/parallel\n",
      "  creating build/lib/apex/fused_dense\n",
      "  copying apex/fused_dense/fused_dense.py -> build/lib/apex/fused_dense\n",
      "  copying apex/fused_dense/__init__.py -> build/lib/apex/fused_dense\n",
      "  creating build/lib/apex/reparameterization\n",
      "  copying apex/reparameterization/reparameterization.py -> build/lib/apex/reparameterization\n",
      "  copying apex/reparameterization/__init__.py -> build/lib/apex/reparameterization\n",
      "  copying apex/reparameterization/weight_norm.py -> build/lib/apex/reparameterization\n",
      "  creating build/lib/apex/RNN\n",
      "  copying apex/RNN/RNNBackend.py -> build/lib/apex/RNN\n",
      "  copying apex/RNN/__init__.py -> build/lib/apex/RNN\n",
      "  copying apex/RNN/models.py -> build/lib/apex/RNN\n",
      "  copying apex/RNN/cells.py -> build/lib/apex/RNN\n",
      "  creating build/lib/apex/normalization\n",
      "  copying apex/normalization/fused_layer_norm.py -> build/lib/apex/normalization\n",
      "  copying apex/normalization/__init__.py -> build/lib/apex/normalization\n",
      "  creating build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_adam.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_sgd.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_lamb.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_novograd.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/__init__.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_adagrad.py -> build/lib/apex/optimizers\n",
      "  creating build/lib/apex/multi_tensor_apply\n",
      "  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib/apex/multi_tensor_apply\n",
      "  copying apex/multi_tensor_apply/__init__.py -> build/lib/apex/multi_tensor_apply\n",
      "  creating build/lib/apex/mlp\n",
      "  copying apex/mlp/mlp.py -> build/lib/apex/mlp\n",
      "  copying apex/mlp/__init__.py -> build/lib/apex/mlp\n",
      "  creating build/lib/apex/contrib\n",
      "  copying apex/contrib/__init__.py -> build/lib/apex/contrib\n",
      "  creating build/lib/apex/fp16_utils\n",
      "  copying apex/fp16_utils/loss_scaler.py -> build/lib/apex/fp16_utils\n",
      "  copying apex/fp16_utils/fp16_optimizer.py -> build/lib/apex/fp16_utils\n",
      "  copying apex/fp16_utils/fp16util.py -> build/lib/apex/fp16_utils\n",
      "  copying apex/fp16_utils/__init__.py -> build/lib/apex/fp16_utils\n",
      "  creating build/lib/apex/amp\n",
      "  copying apex/amp/utils.py -> build/lib/apex/amp\n",
      "  copying apex/amp/amp.py -> build/lib/apex/amp\n",
      "  copying apex/amp/_amp_state.py -> build/lib/apex/amp\n",
      "  copying apex/amp/scaler.py -> build/lib/apex/amp\n",
      "  copying apex/amp/__version__.py -> build/lib/apex/amp\n",
      "  copying apex/amp/opt.py -> build/lib/apex/amp\n",
      "  copying apex/amp/_process_optimizer.py -> build/lib/apex/amp\n",
      "  copying apex/amp/_initialize.py -> build/lib/apex/amp\n",
      "  copying apex/amp/rnn_compat.py -> build/lib/apex/amp\n",
      "  copying apex/amp/frontend.py -> build/lib/apex/amp\n",
      "  copying apex/amp/__init__.py -> build/lib/apex/amp\n",
      "  copying apex/amp/compat.py -> build/lib/apex/amp\n",
      "  copying apex/amp/wrap.py -> build/lib/apex/amp\n",
      "  copying apex/amp/handle.py -> build/lib/apex/amp\n",
      "  creating build/lib/apex/pyprof/nvtx\n",
      "  copying apex/pyprof/nvtx/nvmarker.py -> build/lib/apex/pyprof/nvtx\n",
      "  copying apex/pyprof/nvtx/__init__.py -> build/lib/apex/pyprof/nvtx\n",
      "  creating build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/randomSample.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/recurrentCell.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/embedding.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/conv.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/optim.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/normalization.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/softmax.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/usage.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/data.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/loss.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/blas.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/output.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/convert.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/dropout.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/__init__.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/misc.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/base.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/utility.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/prof.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/__main__.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/pointwise.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/reduction.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/activation.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/pooling.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/linear.py -> build/lib/apex/pyprof/prof\n",
      "  creating build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/db.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/__init__.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/parse.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/kernel.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/__main__.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/nvvp.py -> build/lib/apex/pyprof/parse\n",
      "  creating build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/__init__.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  creating build/lib/apex/contrib/fmha\n",
      "  copying apex/contrib/fmha/fmha.py -> build/lib/apex/contrib/fmha\n",
      "  copying apex/contrib/fmha/__init__.py -> build/lib/apex/contrib/fmha\n",
      "  creating build/lib/apex/contrib/groupbn\n",
      "  copying apex/contrib/groupbn/__init__.py -> build/lib/apex/contrib/groupbn\n",
      "  copying apex/contrib/groupbn/batch_norm.py -> build/lib/apex/contrib/groupbn\n",
      "  creating build/lib/apex/contrib/layer_norm\n",
      "  copying apex/contrib/layer_norm/layer_norm.py -> build/lib/apex/contrib/layer_norm\n",
      "  copying apex/contrib/layer_norm/__init__.py -> build/lib/apex/contrib/layer_norm\n",
      "  creating build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fused_adam.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fused_sgd.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/__init__.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib/apex/contrib/optimizers\n",
      "  creating build/lib/apex/contrib/bottleneck\n",
      "  copying apex/contrib/bottleneck/bottleneck.py -> build/lib/apex/contrib/bottleneck\n",
      "  copying apex/contrib/bottleneck/bottleneck_module_test.py -> build/lib/apex/contrib/bottleneck\n",
      "  copying apex/contrib/bottleneck/__init__.py -> build/lib/apex/contrib/bottleneck\n",
      "  copying apex/contrib/bottleneck/test.py -> build/lib/apex/contrib/bottleneck\n",
      "  creating build/lib/apex/contrib/transducer\n",
      "  copying apex/contrib/transducer/__init__.py -> build/lib/apex/contrib/transducer\n",
      "  copying apex/contrib/transducer/transducer.py -> build/lib/apex/contrib/transducer\n",
      "  creating build/lib/apex/contrib/xentropy\n",
      "  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib/apex/contrib/xentropy\n",
      "  copying apex/contrib/xentropy/__init__.py -> build/lib/apex/contrib/xentropy\n",
      "  creating build/lib/apex/contrib/sparsity\n",
      "  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib/apex/contrib/sparsity\n",
      "  copying apex/contrib/sparsity/asp.py -> build/lib/apex/contrib/sparsity\n",
      "  copying apex/contrib/sparsity/__init__.py -> build/lib/apex/contrib/sparsity\n",
      "  creating build/lib/apex/amp/lists\n",
      "  copying apex/amp/lists/tensor_overrides.py -> build/lib/apex/amp/lists\n",
      "  copying apex/amp/lists/__init__.py -> build/lib/apex/amp/lists\n",
      "  copying apex/amp/lists/functional_overrides.py -> build/lib/apex/amp/lists\n",
      "  copying apex/amp/lists/torch_overrides.py -> build/lib/apex/amp/lists\n",
      "  installing to build/bdist.linux-x86_64/wheel\n",
      "  running install\n",
      "  running install_lib\n",
      "  creating build/bdist.linux-x86_64\n",
      "  creating build/bdist.linux-x86_64/wheel\n",
      "  creating build/bdist.linux-x86_64/wheel/apex\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/pyprof\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
      "  copying build/lib/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
      "  copying build/lib/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/fused_dense\n",
      "  copying build/lib/apex/fused_dense/fused_dense.py -> build/bdist.linux-x86_64/wheel/apex/fused_dense\n",
      "  copying build/lib/apex/fused_dense/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fused_dense\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
      "  copying build/lib/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
      "  copying build/lib/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
      "  copying build/lib/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/RNN\n",
      "  copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
      "  copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
      "  copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
      "  copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/normalization\n",
      "  copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
      "  copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
      "  copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
      "  copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/mlp\n",
      "  copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
      "  copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
      "  copying build/lib/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
      "  copying build/lib/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
      "  copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
      "  copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
      "  copying build/lib/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
      "  copying build/lib/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
      "  copying build/lib/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
      "  copying build/lib/apex/contrib/bottleneck/bottleneck_module_test.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
      "  copying build/lib/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
      "  copying build/lib/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
      "  copying build/lib/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
      "  copying build/lib/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
      "  copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
      "  copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
      "  copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
      "  copying build/lib/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
      "  copying build/lib/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
      "  copying build/lib/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
      "  copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
      "  copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
      "  copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
      "  copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
      "  copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
      "  copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
      "  copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
      "  copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
      "  copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
      "  copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  running install_egg_info\n",
      "  running egg_info\n",
      "  creating apex.egg-info\n",
      "  writing apex.egg-info/PKG-INFO\n",
      "  writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "  writing top-level names to apex.egg-info/top_level.txt\n",
      "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "  reading manifest file 'apex.egg-info/SOURCES.txt'\n",
      "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.7.egg-info\n",
      "  running install_scripts\n",
      "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
      "  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n",
      "  creating '/tmp/pip-wheel-_hx7yt3_/apex-0.1-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
      "  adding 'apex/__init__.py'\n",
      "  adding 'apex/RNN/RNNBackend.py'\n",
      "  adding 'apex/RNN/__init__.py'\n",
      "  adding 'apex/RNN/cells.py'\n",
      "  adding 'apex/RNN/models.py'\n",
      "  adding 'apex/amp/__init__.py'\n",
      "  adding 'apex/amp/__version__.py'\n",
      "  adding 'apex/amp/_amp_state.py'\n",
      "  adding 'apex/amp/_initialize.py'\n",
      "  adding 'apex/amp/_process_optimizer.py'\n",
      "  adding 'apex/amp/amp.py'\n",
      "  adding 'apex/amp/compat.py'\n",
      "  adding 'apex/amp/frontend.py'\n",
      "  adding 'apex/amp/handle.py'\n",
      "  adding 'apex/amp/opt.py'\n",
      "  adding 'apex/amp/rnn_compat.py'\n",
      "  adding 'apex/amp/scaler.py'\n",
      "  adding 'apex/amp/utils.py'\n",
      "  adding 'apex/amp/wrap.py'\n",
      "  adding 'apex/amp/lists/__init__.py'\n",
      "  adding 'apex/amp/lists/functional_overrides.py'\n",
      "  adding 'apex/amp/lists/tensor_overrides.py'\n",
      "  adding 'apex/amp/lists/torch_overrides.py'\n",
      "  adding 'apex/contrib/__init__.py'\n",
      "  adding 'apex/contrib/bottleneck/__init__.py'\n",
      "  adding 'apex/contrib/bottleneck/bottleneck.py'\n",
      "  adding 'apex/contrib/bottleneck/bottleneck_module_test.py'\n",
      "  adding 'apex/contrib/bottleneck/test.py'\n",
      "  adding 'apex/contrib/fmha/__init__.py'\n",
      "  adding 'apex/contrib/fmha/fmha.py'\n",
      "  adding 'apex/contrib/groupbn/__init__.py'\n",
      "  adding 'apex/contrib/groupbn/batch_norm.py'\n",
      "  adding 'apex/contrib/layer_norm/__init__.py'\n",
      "  adding 'apex/contrib/layer_norm/layer_norm.py'\n",
      "  adding 'apex/contrib/multihead_attn/__init__.py'\n",
      "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'\n",
      "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/self_multihead_attn.py'\n",
      "  adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'\n",
      "  adding 'apex/contrib/optimizers/__init__.py'\n",
      "  adding 'apex/contrib/optimizers/distributed_fused_adam.py'\n",
      "  adding 'apex/contrib/optimizers/distributed_fused_adam_v2.py'\n",
      "  adding 'apex/contrib/optimizers/distributed_fused_adam_v3.py'\n",
      "  adding 'apex/contrib/optimizers/distributed_fused_lamb.py'\n",
      "  adding 'apex/contrib/optimizers/fp16_optimizer.py'\n",
      "  adding 'apex/contrib/optimizers/fused_adam.py'\n",
      "  adding 'apex/contrib/optimizers/fused_lamb.py'\n",
      "  adding 'apex/contrib/optimizers/fused_sgd.py'\n",
      "  adding 'apex/contrib/sparsity/__init__.py'\n",
      "  adding 'apex/contrib/sparsity/asp.py'\n",
      "  adding 'apex/contrib/sparsity/sparse_masklib.py'\n",
      "  adding 'apex/contrib/transducer/__init__.py'\n",
      "  adding 'apex/contrib/transducer/transducer.py'\n",
      "  adding 'apex/contrib/xentropy/__init__.py'\n",
      "  adding 'apex/contrib/xentropy/softmax_xentropy.py'\n",
      "  adding 'apex/fp16_utils/__init__.py'\n",
      "  adding 'apex/fp16_utils/fp16_optimizer.py'\n",
      "  adding 'apex/fp16_utils/fp16util.py'\n",
      "  adding 'apex/fp16_utils/loss_scaler.py'\n",
      "  adding 'apex/fused_dense/__init__.py'\n",
      "  adding 'apex/fused_dense/fused_dense.py'\n",
      "  adding 'apex/mlp/__init__.py'\n",
      "  adding 'apex/mlp/mlp.py'\n",
      "  adding 'apex/multi_tensor_apply/__init__.py'\n",
      "  adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n",
      "  adding 'apex/normalization/__init__.py'\n",
      "  adding 'apex/normalization/fused_layer_norm.py'\n",
      "  adding 'apex/optimizers/__init__.py'\n",
      "  adding 'apex/optimizers/fused_adagrad.py'\n",
      "  adding 'apex/optimizers/fused_adam.py'\n",
      "  adding 'apex/optimizers/fused_lamb.py'\n",
      "  adding 'apex/optimizers/fused_novograd.py'\n",
      "  adding 'apex/optimizers/fused_sgd.py'\n",
      "  adding 'apex/parallel/LARC.py'\n",
      "  adding 'apex/parallel/__init__.py'\n",
      "  adding 'apex/parallel/distributed.py'\n",
      "  adding 'apex/parallel/multiproc.py'\n",
      "  adding 'apex/parallel/optimized_sync_batchnorm.py'\n",
      "  adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n",
      "  adding 'apex/parallel/sync_batchnorm.py'\n",
      "  adding 'apex/parallel/sync_batchnorm_kernel.py'\n",
      "  adding 'apex/pyprof/__init__.py'\n",
      "  adding 'apex/pyprof/nvtx/__init__.py'\n",
      "  adding 'apex/pyprof/nvtx/nvmarker.py'\n",
      "  adding 'apex/pyprof/parse/__init__.py'\n",
      "  adding 'apex/pyprof/parse/__main__.py'\n",
      "  adding 'apex/pyprof/parse/db.py'\n",
      "  adding 'apex/pyprof/parse/kernel.py'\n",
      "  adding 'apex/pyprof/parse/nvvp.py'\n",
      "  adding 'apex/pyprof/parse/parse.py'\n",
      "  adding 'apex/pyprof/prof/__init__.py'\n",
      "  adding 'apex/pyprof/prof/__main__.py'\n",
      "  adding 'apex/pyprof/prof/activation.py'\n",
      "  adding 'apex/pyprof/prof/base.py'\n",
      "  adding 'apex/pyprof/prof/blas.py'\n",
      "  adding 'apex/pyprof/prof/conv.py'\n",
      "  adding 'apex/pyprof/prof/convert.py'\n",
      "  adding 'apex/pyprof/prof/data.py'\n",
      "  adding 'apex/pyprof/prof/dropout.py'\n",
      "  adding 'apex/pyprof/prof/embedding.py'\n",
      "  adding 'apex/pyprof/prof/index_slice_join_mutate.py'\n",
      "  adding 'apex/pyprof/prof/linear.py'\n",
      "  adding 'apex/pyprof/prof/loss.py'\n",
      "  adding 'apex/pyprof/prof/misc.py'\n",
      "  adding 'apex/pyprof/prof/normalization.py'\n",
      "  adding 'apex/pyprof/prof/optim.py'\n",
      "  adding 'apex/pyprof/prof/output.py'\n",
      "  adding 'apex/pyprof/prof/pointwise.py'\n",
      "  adding 'apex/pyprof/prof/pooling.py'\n",
      "  adding 'apex/pyprof/prof/prof.py'\n",
      "  adding 'apex/pyprof/prof/randomSample.py'\n",
      "  adding 'apex/pyprof/prof/recurrentCell.py'\n",
      "  adding 'apex/pyprof/prof/reduction.py'\n",
      "  adding 'apex/pyprof/prof/softmax.py'\n",
      "  adding 'apex/pyprof/prof/usage.py'\n",
      "  adding 'apex/pyprof/prof/utility.py'\n",
      "  adding 'apex/reparameterization/__init__.py'\n",
      "  adding 'apex/reparameterization/reparameterization.py'\n",
      "  adding 'apex/reparameterization/weight_norm.py'\n",
      "  adding 'apex-0.1.dist-info/LICENSE'\n",
      "  adding 'apex-0.1.dist-info/METADATA'\n",
      "  adding 'apex-0.1.dist-info/WHEEL'\n",
      "  adding 'apex-0.1.dist-info/top_level.txt'\n",
      "  adding 'apex-0.1.dist-info/RECORD'\n",
      "  removing build/bdist.linux-x86_64/wheel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for apex: filename=apex-0.1-py3-none-any.whl size=211574 sha256=9beb6980ca043cb1da61a82a7351c86d7898710e4bb615cd7f21c9d5c89244a0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-yhiunjru/wheels/e2/1d/1a/da4b5f60430fe54b48218ccf1705246f66a43e5acd7fa7458d\n",
      "Successfully built apex\n",
      "Installing collected packages: apex\n",
      "  Attempting uninstall: apex\n",
      "    Found existing installation: apex 0.1\n",
      "    Uninstalling apex-0.1:\n",
      "      Removing file or directory /home/karem/anaconda3/envs/env_yolox/lib/python3.7/site-packages/apex-0.1.dist-info/\n",
      "      Removing file or directory /home/karem/anaconda3/envs/env_yolox/lib/python3.7/site-packages/apex/\n",
      "      Successfully uninstalled apex-0.1\n",
      "Successfully installed apex-0.1\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "## Install Nvidia Apex\n",
    "#######################################################\n",
    "\n",
    "# Muda o diretório \n",
    "# arquivo original  = /content/  --> google colab        mudar para: /home/karem/Artigo_Periodico/YoloX/\n",
    "%cd /home/karem/Artigo_Periodico/YoloX/\n",
    "!git clone https://github.com/NVIDIA/apex\n",
    "\n",
    "\n",
    "%cd apex\n",
    "!pip install -v --disable-pip-version-check --no-cache-dir ./\n",
    "# ## Versão inicial de instalção - fornece erros no apex\n",
    "# !pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5641f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cython in /home/karem/anaconda3/envs/env_yolox/lib/python3.7/site-packages (0.29.24)\n",
      "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
      "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-4xz_k_5m\n",
      "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-4xz_k_5m\n",
      "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
      "Requirement already satisfied: setuptools>=18.0 in /home/karem/anaconda3/envs/env_yolox/lib/python3.7/site-packages (from pycocotools==2.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: cython>=0.27.3 in /home/karem/anaconda3/envs/env_yolox/lib/python3.7/site-packages (from pycocotools==2.0) (0.29.24)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /home/karem/anaconda3/envs/env_yolox/lib/python3.7/site-packages (from pycocotools==2.0) (3.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/karem/anaconda3/envs/env_yolox/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /home/karem/anaconda3/envs/env_yolox/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.21.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/karem/anaconda3/envs/env_yolox/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/karem/anaconda3/envs/env_yolox/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/karem/anaconda3/envs/env_yolox/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/karem/anaconda3/envs/env_yolox/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (8.3.2)\n",
      "Requirement already satisfied: six in /home/karem/anaconda3/envs/env_yolox/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "## Install PyCocoTools\n",
    "#######################################################\n",
    "\n",
    "!pip3 install cython; pip3 install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2388610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "## Download Dataset\n",
    "#######################################################\n",
    "\n",
    "#We'll download our dataset from Roboflow. Use the \"Pascal VOC\" export format.\n",
    "# To get your data into Roboflow, follow the Getting Started Guide.\n",
    "# (https://blog.roboflow.com/getting-started-with-roboflow/)\n",
    "\n",
    "\n",
    "# ## Dataset de células sanguíneas (arquivo YoloX original)\n",
    "# %cd /home/karem/Artigo_Periodico/YoloX/\n",
    "# !curl -L https://public.roboflow.com/ds/EyEFKj1tmv?key=MyKUCznSvm > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12aeeccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "## Dataset - Covid\n",
    "#######################################################\n",
    "\n",
    "# # Move as imagens e os labels em xml que foram separados entre treino, val e teste para a pasta da Yolo\n",
    "\n",
    "# import subprocess\n",
    "\n",
    "# ## Define a pasta\n",
    "# conj = ['train/', 'valid/', 'test/']\n",
    "\n",
    "# for i in range(len(conj)):\n",
    "    \n",
    "#     ## define your paths\n",
    "#     source_image = path_Yolo + 'Dados/images/' + conj[i] # path1\n",
    "#     source_xml = path_Yolo + 'Dados/labels_xml/' + conj[i] # path2   \n",
    "#     dest_data = path_Yolo + conj[i] ## where to place the merged data\n",
    "    \n",
    "#     ## write an rsync commands to merge the directories\n",
    "#     rsync_cmd = 'rsync' + ' -avzh ' + source_image + ' ' + source_xml + ' ' + dest_data\n",
    "\n",
    "#     ## run the rsync command\n",
    "#     subprocess.run(rsync_cmd, shell=True)\n",
    "    \n",
    "############# Esse processo faz a separação automática (train, val e test) dos arquivos contidos na pasta train\n",
    "## ou seja, 90% para train e val; 10% para test. \n",
    "## Dos 90% de train e val -> 80% para train e 20% para val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c55ca31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/karem/Artigo_Periodico/YoloX/YOLOX\n"
     ]
    }
   ],
   "source": [
    "%cd /home/karem/Artigo_Periodico/YoloX/YOLOX/\n",
    "\n",
    "# Liga as pastas com as imagens de treino e a VOCdevkit\n",
    "# Tudo o que for alterado em uma, será alterado na outra\n",
    "!ln -s /home/karem/Artigo_Periodico/YoloX/train/ ./datasets/VOCdevkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bae0caba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and val size: 5075\r\n",
      "train size: 4060\r\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "## Format Your Data Appropriately\n",
    "#######################################################\n",
    "\n",
    "%mkdir \"/home/karem/Artigo_Periodico/YoloX/YOLOX/datasets/VOCdevkit/VOC2007/\"\n",
    "!python3 voc_txt.py \"/home/karem/Artigo_Periodico/YoloX/YOLOX/datasets/VOCdevkit/\"\n",
    "%mkdir \"/home/karem/Artigo_Periodico/YoloX/YOLOX/datasets/VOCdevkit/VOC2012/\"\n",
    "!cp -r \"/home/karem/Artigo_Periodico/YoloX/YOLOX/datasets/VOCdevkit/VOC2007/.\" \"/home/karem/Artigo_Periodico/YoloX/YOLOX/datasets/VOCdevkit/VOC2012\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "444d816e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO_CLASSES = (\"covid\",\"normal\")"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "## Change the Classes\n",
    "#######################################################\n",
    "\n",
    "# from IPython.core.magic import register_line_cell_magic\n",
    "# @register_line_cell_magic\n",
    "# def writetemplate(line, cell):\n",
    "#     with open(line, 'w') as f:\n",
    "#         f.write(cell.format(**globals()))\n",
    "\n",
    "\n",
    "# ##REPLACE this cell with your classnames stripped of whitespace and lowercase\n",
    "# %%writetemplate /content/YOLOX/yolox/data/datasets/voc_classes.py\n",
    "\n",
    "# VOC_CLASSES = (\n",
    "#   \"rbc\",\n",
    "#   \"wbc\",\n",
    "#   \"platelets\"\n",
    "# )\n",
    "\n",
    "\n",
    "# ##REPLACE this cell with your classnames stripped of whitespace and lowercase\n",
    "# %%writetemplate /content/YOLOX/yolox/data/datasets/coco_classes.py\n",
    "\n",
    "# COCO_CLASSES = (\n",
    "#   \"rbc\",\n",
    "#   \"wbc\",\n",
    "#   \"platelets\"\n",
    "# )\n",
    "\n",
    "\n",
    "# Mostra as classes (arquivo original)\n",
    "# %cat /home/karem/Artigo_Periodico/YoloX/YOLOX/yolox/data/datasets/voc_classes.py\n",
    "\n",
    "\n",
    "# # Dataset original\n",
    "# f = open(\"/home/karem/Artigo_Periodico/YoloX/YOLOX/yolox/data/datasets/voc_classes.py\", \"w\")\n",
    "# f.write('VOC_CLASSES = (\"rbc\",\"wbc\",\"platelets\")')\n",
    "# f.close()\n",
    "\n",
    "# f = open(\"/home/karem/Artigo_Periodico/YoloX/YOLOX/yolox/data/datasets/coco_classes.py\", \"w\")\n",
    "# f.write('COCO_CLASSES = (\"rbc\",\"wbc\",\"platelets\")')\n",
    "# f.close()\n",
    "\n",
    "\n",
    "\n",
    "f = open(\"/home/karem/Artigo_Periodico/YoloX/YOLOX/yolox/data/datasets/voc_classes.py\", \"w\")\n",
    "#f.write('VOC_CLASSES = (\"covid\")')\n",
    "f.write('VOC_CLASSES = (\"covid\",\"normal\")')\n",
    "f.close()\n",
    "\n",
    "f = open(\"/home/karem/Artigo_Periodico/YoloX/YOLOX/yolox/data/datasets/coco_classes.py\", \"w\")\n",
    "#f.write('COCO_CLASSES = (\"covid\")')\n",
    "f.write('COCO_CLASSES = (\"covid\",\"normal\")')\n",
    "f.close()\n",
    "\n",
    "\n",
    "# Mostra as classes após a alteração no arquivo py classes e coco\n",
    "# %cat /home/karem/Artigo_Periodico/YoloX/YOLOX/yolox/data/datasets/voc_classes.py\n",
    "%cat /home/karem/Artigo_Periodico/YoloX/YOLOX/yolox/data/datasets/coco_classes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ef3968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of classes you have in your dataset in te NUM_CLASSES variable\n",
    "# NUM_CLASSES = 3 # dataset original\n",
    "NUM_CLASSES = 2\n",
    "!sed -i -e 's/self.num_classes = 20/self.num_classes = {NUM_CLASSES}/g' \"/home/karem/Artigo_Periodico/YoloX/YOLOX/exps/example/yolox_voc/yolox_voc_s.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e53ea19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/karem/Artigo_Periodico/YoloX\n",
      "--2021-09-17 19:35:34--  https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_s.pth\n",
      "Resolving github.com (github.com)... 20.201.28.151\n",
      "Connecting to github.com (github.com)|20.201.28.151|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-releases.githubusercontent.com/388351473/0b307dd4-bddb-4cfe-a863-1d19afb5598a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210917%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210917T143231Z&X-Amz-Expires=300&X-Amz-Signature=098cbb03189b64793adc6cffc2904917423a6f5fca28b0842f255b96b102fbe3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=388351473&response-content-disposition=attachment%3B%20filename%3Dyolox_s.pth&response-content-type=application%2Foctet-stream [following]\n",
      "--2021-09-17 19:35:35--  https://github-releases.githubusercontent.com/388351473/0b307dd4-bddb-4cfe-a863-1d19afb5598a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210917%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210917T143231Z&X-Amz-Expires=300&X-Amz-Signature=098cbb03189b64793adc6cffc2904917423a6f5fca28b0842f255b96b102fbe3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=388351473&response-content-disposition=attachment%3B%20filename%3Dyolox_s.pth&response-content-type=application%2Foctet-stream\n",
      "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.111.154, 185.199.108.154, 185.199.109.154, ...\n",
      "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.111.154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 72050245 (69M) [application/octet-stream]\n",
      "Saving to: ‘yolox_s.pth’\n",
      "\n",
      "yolox_s.pth         100%[===================>]  68.71M  26.4MB/s    in 2.6s    \n",
      "\n",
      "2021-09-17 19:35:38 (26.4 MB/s) - ‘yolox_s.pth’ saved [72050245/72050245]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "## Download Pretrained Weights\n",
    "#######################################################\n",
    "\n",
    "%cd /home/karem/Artigo_Periodico/YoloX/\n",
    "!wget https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_s.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbbb8d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/karem/Artigo_Periodico/YoloX/YOLOX\n",
      "\u001b[32m2021-09-17 19:35:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1margs: Namespace(batch_size=16, ckpt='/home/karem/Artigo_Periodico/YoloX/yolox_s.pth', devices=1, dist_backend='nccl', dist_url=None, exp_file='exps/example/yolox_voc/yolox_voc_s.py', experiment_name='yolox_voc_s', fp16=True, local_rank=0, machine_rank=0, name=None, num_machines=1, occupy=True, opts=[], resume=False, start_epoch=None)\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mexp value:\n",
      "╒══════════════════╤════════════════════════════╕\n",
      "│ keys             │ values                     │\n",
      "╞══════════════════╪════════════════════════════╡\n",
      "│ seed             │ None                       │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ output_dir       │ './YOLOX_outputs'          │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ print_interval   │ 10                         │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ eval_interval    │ 10                         │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ num_classes      │ 2                          │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ depth            │ 0.33                       │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ width            │ 0.5                        │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ data_num_workers │ 4                          │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ input_size       │ (640, 640)                 │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ random_size      │ (14, 26)                   │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ train_ann        │ 'instances_train2017.json' │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ val_ann          │ 'instances_val2017.json'   │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ degrees          │ 10.0                       │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ translate        │ 0.1                        │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ scale            │ (0.1, 2)                   │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ mscale           │ (0.8, 1.6)                 │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ shear            │ 2.0                        │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ perspective      │ 0.0                        │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ enable_mixup     │ True                       │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ warmup_epochs    │ 5                          │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ max_epoch        │ 300                        │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ warmup_lr        │ 0                          │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ basic_lr_per_img │ 0.00015625                 │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ scheduler        │ 'yoloxwarmcos'             │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ no_aug_epochs    │ 15                         │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ min_lr_ratio     │ 0.05                       │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ ema              │ True                       │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ weight_decay     │ 0.0005                     │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ momentum         │ 0.9                        │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ exp_name         │ 'yolox_voc_s'              │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ test_size        │ (640, 640)                 │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ test_conf        │ 0.01                       │\n",
      "├──────────────────┼────────────────────────────┤\n",
      "│ nmsthre          │ 0.65                       │\n",
      "╘══════════════════╧════════════════════════════╛\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m132\u001b[0m - \u001b[1mModel Summary: Params: 8.94M, Gflops: 26.64\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1mSelected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mDefaults for this optimization level are:\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1menabled                : True\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mopt_level              : O1\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mcast_model_type        : None\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mpatch_torch_functions  : True\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mkeep_batchnorm_fp32    : None\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mmaster_weights         : None\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mloss_scale             : dynamic\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mProcessing user overrides (additional kwargs that are not None)...\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mAfter processing overrides, optimization options are:\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1menabled                : True\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mopt_level              : O1\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mcast_model_type        : None\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mpatch_torch_functions  : True\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mkeep_batchnorm_fp32    : None\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mmaster_weights         : None\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mloss_scale             : dynamic\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.scaler\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mWarning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m297\u001b[0m - \u001b[1mloading checkpoint for fine tuning\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36myolox.utils.checkpoint\u001b[0m:\u001b[36m27\u001b[0m - \u001b[33m\u001b[1mShape of head.cls_preds.0.weight in checkpoint is torch.Size([80, 128, 1, 1]), while shape of head.cls_preds.0.weight in model is torch.Size([2, 128, 1, 1]).\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36myolox.utils.checkpoint\u001b[0m:\u001b[36m27\u001b[0m - \u001b[33m\u001b[1mShape of head.cls_preds.0.bias in checkpoint is torch.Size([80]), while shape of head.cls_preds.0.bias in model is torch.Size([2]).\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36myolox.utils.checkpoint\u001b[0m:\u001b[36m27\u001b[0m - \u001b[33m\u001b[1mShape of head.cls_preds.1.weight in checkpoint is torch.Size([80, 128, 1, 1]), while shape of head.cls_preds.1.weight in model is torch.Size([2, 128, 1, 1]).\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36myolox.utils.checkpoint\u001b[0m:\u001b[36m27\u001b[0m - \u001b[33m\u001b[1mShape of head.cls_preds.1.bias in checkpoint is torch.Size([80]), while shape of head.cls_preds.1.bias in model is torch.Size([2]).\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36myolox.utils.checkpoint\u001b[0m:\u001b[36m27\u001b[0m - \u001b[33m\u001b[1mShape of head.cls_preds.2.weight in checkpoint is torch.Size([80, 128, 1, 1]), while shape of head.cls_preds.2.weight in model is torch.Size([2, 128, 1, 1]).\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36myolox.utils.checkpoint\u001b[0m:\u001b[36m27\u001b[0m - \u001b[33m\u001b[1mShape of head.cls_preds.2.bias in checkpoint is torch.Size([80]), while shape of head.cls_preds.2.bias in model is torch.Size([2]).\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1minit prefetcher, this might take one minute or less...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-09-17 19:35:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m182\u001b[0m - \u001b[1mTraining start...\u001b[0m\r\n",
      "\u001b[32m2021-09-17 19:35:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1m\r\n",
      "YOLOX(\r\n",
      "  (backbone): YOLOPAFPN(\r\n",
      "    (backbone): CSPDarknet(\r\n",
      "      (stem): Focus(\r\n",
      "        (conv): BaseConv(\r\n",
      "          (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (dark2): Sequential(\r\n",
      "        (0): BaseConv(\r\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (1): CSPLayer(\r\n",
      "          (conv1): BaseConv(\r\n",
      "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (conv2): BaseConv(\r\n",
      "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (conv3): BaseConv(\r\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (m): Sequential(\r\n",
      "            (0): Bottleneck(\r\n",
      "              (conv1): BaseConv(\r\n",
      "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "                (act): SiLU(inplace=True)\r\n",
      "              )\r\n",
      "              (conv2): BaseConv(\r\n",
      "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "                (act): SiLU(inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (dark3): Sequential(\r\n",
      "        (0): BaseConv(\r\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (1): CSPLayer(\r\n",
      "          (conv1): BaseConv(\r\n",
      "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (conv2): BaseConv(\r\n",
      "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (conv3): BaseConv(\r\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (m): Sequential(\r\n",
      "            (0): Bottleneck(\r\n",
      "              (conv1): BaseConv(\r\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "                (act): SiLU(inplace=True)\r\n",
      "              )\r\n",
      "              (conv2): BaseConv(\r\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "                (act): SiLU(inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (1): Bottleneck(\r\n",
      "              (conv1): BaseConv(\r\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "                (act): SiLU(inplace=True)\r\n",
      "              )\r\n",
      "              (conv2): BaseConv(\r\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "                (act): SiLU(inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (2): Bottleneck(\r\n",
      "              (conv1): BaseConv(\r\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "                (act): SiLU(inplace=True)\r\n",
      "              )\r\n",
      "              (conv2): BaseConv(\r\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "                (act): SiLU(inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (dark4): Sequential(\r\n",
      "        (0): BaseConv(\r\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (1): CSPLayer(\r\n",
      "          (conv1): BaseConv(\r\n",
      "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (conv2): BaseConv(\r\n",
      "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (conv3): BaseConv(\r\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (m): Sequential(\r\n",
      "            (0): Bottleneck(\r\n",
      "              (conv1): BaseConv(\r\n",
      "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "                (act): SiLU(inplace=True)\r\n",
      "              )\r\n",
      "              (conv2): BaseConv(\r\n",
      "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "                (act): SiLU(inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (1): Bottleneck(\r\n",
      "              (conv1): BaseConv(\r\n",
      "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "                (act): SiLU(inplace=True)\r\n",
      "              )\r\n",
      "              (conv2): BaseConv(\r\n",
      "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "                (act): SiLU(inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (2): Bottleneck(\r\n",
      "              (conv1): BaseConv(\r\n",
      "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "                (act): SiLU(inplace=True)\r\n",
      "              )\r\n",
      "              (conv2): BaseConv(\r\n",
      "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "                (act): SiLU(inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (dark5): Sequential(\r\n",
      "        (0): BaseConv(\r\n",
      "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (1): SPPBottleneck(\r\n",
      "          (conv1): BaseConv(\r\n",
      "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (m): ModuleList(\r\n",
      "            (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\r\n",
      "            (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\r\n",
      "            (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\r\n",
      "          )\r\n",
      "          (conv2): BaseConv(\r\n",
      "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (2): CSPLayer(\r\n",
      "          (conv1): BaseConv(\r\n",
      "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (conv2): BaseConv(\r\n",
      "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (conv3): BaseConv(\r\n",
      "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (m): Sequential(\r\n",
      "            (0): Bottleneck(\r\n",
      "              (conv1): BaseConv(\r\n",
      "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "                (act): SiLU(inplace=True)\r\n",
      "              )\r\n",
      "              (conv2): BaseConv(\r\n",
      "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "                (act): SiLU(inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (upsample): Upsample(scale_factor=2.0, mode=nearest)\r\n",
      "    (lateral_conv0): BaseConv(\r\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (C3_p4): CSPLayer(\r\n",
      "      (conv1): BaseConv(\r\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (conv2): BaseConv(\r\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (conv3): BaseConv(\r\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (m): Sequential(\r\n",
      "        (0): Bottleneck(\r\n",
      "          (conv1): BaseConv(\r\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (conv2): BaseConv(\r\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (reduce_conv1): BaseConv(\r\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (C3_p3): CSPLayer(\r\n",
      "      (conv1): BaseConv(\r\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (conv2): BaseConv(\r\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (conv3): BaseConv(\r\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (m): Sequential(\r\n",
      "        (0): Bottleneck(\r\n",
      "          (conv1): BaseConv(\r\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (conv2): BaseConv(\r\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (bu_conv2): BaseConv(\r\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (C3_n3): CSPLayer(\r\n",
      "      (conv1): BaseConv(\r\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (conv2): BaseConv(\r\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (conv3): BaseConv(\r\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (m): Sequential(\r\n",
      "        (0): Bottleneck(\r\n",
      "          (conv1): BaseConv(\r\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (conv2): BaseConv(\r\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (bu_conv1): BaseConv(\r\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (C3_n4): CSPLayer(\r\n",
      "      (conv1): BaseConv(\r\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (conv2): BaseConv(\r\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (conv3): BaseConv(\r\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (m): Sequential(\r\n",
      "        (0): Bottleneck(\r\n",
      "          (conv1): BaseConv(\r\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (conv2): BaseConv(\r\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (head): YOLOXHead(\r\n",
      "    (cls_convs): ModuleList(\r\n",
      "      (0): Sequential(\r\n",
      "        (0): BaseConv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (1): BaseConv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (1): Sequential(\r\n",
      "        (0): BaseConv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (1): BaseConv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (2): Sequential(\r\n",
      "        (0): BaseConv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (1): BaseConv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (reg_convs): ModuleList(\r\n",
      "      (0): Sequential(\r\n",
      "        (0): BaseConv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (1): BaseConv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (1): Sequential(\r\n",
      "        (0): BaseConv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (1): BaseConv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (2): Sequential(\r\n",
      "        (0): BaseConv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (1): BaseConv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (cls_preds): ModuleList(\r\n",
      "      (0): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "      (1): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "      (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "    )\r\n",
      "    (reg_preds): ModuleList(\r\n",
      "      (0): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "      (2): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "    )\r\n",
      "    (obj_preds): ModuleList(\r\n",
      "      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "      (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "      (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "    )\r\n",
      "    (stems): ModuleList(\r\n",
      "      (0): BaseConv(\r\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (1): BaseConv(\r\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (2): BaseConv(\r\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (l1_loss): L1Loss()\r\n",
      "    (bcewithlog_loss): BCEWithLogitsLoss()\r\n",
      "    (iou_loss): IOUloss()\r\n",
      "  )\r\n",
      ")\u001b[0m\r\n",
      "\u001b[32m2021-09-17 19:35:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1m---> start train epoch1\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-09-17 19:35:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.handle\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.handle\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.handle\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.handle\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.handle\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 1/300, iter: 10/635, mem: 20348Mb, iter_time: 0.320s, data_time: 0.001s, total_loss: 13.2, iou_loss: 3.7, l1_loss: 0.0, conf_loss: 7.2, cls_loss: 2.3, lr: 2.480e-08, size: 640, ETA: 16:54:33\u001b[0m\n",
      "\u001b[32m2021-09-17 19:35:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 1/300, iter: 20/635, mem: 20348Mb, iter_time: 0.376s, data_time: 0.001s, total_loss: 13.5, iou_loss: 3.5, l1_loss: 0.0, conf_loss: 7.4, cls_loss: 2.6, lr: 9.920e-08, size: 704, ETA: 18:23:54\u001b[0m\n",
      "\u001b[32m2021-09-17 19:36:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 1/300, iter: 30/635, mem: 20348Mb, iter_time: 0.420s, data_time: 0.001s, total_loss: 13.2, iou_loss: 3.3, l1_loss: 0.0, conf_loss: 7.4, cls_loss: 2.5, lr: 2.232e-07, size: 800, ETA: 19:39:58\u001b[0m\n",
      "^C\n",
      "\u001b[32m2021-09-17 19:36:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m188\u001b[0m - \u001b[1mTraining of experiment is done and the best AP is 0.00\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "%cd /home/karem/Artigo_Periodico/YoloX/YOLOX/\n",
    "!python tools/train.py -f exps/example/yolox_voc/yolox_voc_s.py -d 1 -b 16 --fp16 -o -c /home/karem/Artigo_Periodico/YoloX/yolox_s.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa970a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#######################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
